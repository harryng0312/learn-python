{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:15:36.793163Z",
     "start_time": "2024-08-12T15:15:35.145725Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "import random as rd\n",
    "\n",
    "from array import array\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# my project\n",
    "from module.conf import PROJECT_DIR\n",
    "\n",
    "# %matplotlib tk\n",
    "%matplotlib inline\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data:\n",
    "- Train data: 60k 28x28 images\n",
    "- Test data: "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:15:40.414691Z",
     "start_time": "2024-08-12T15:15:40.403191Z"
    }
   },
   "source": [
    "mnist_path = \"/data/sample/mnist\"\n",
    "training_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-images.idx3-ubyte\"])\n",
    "training_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-labels.idx1-ubyte\"])\n",
    "test_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-images.idx3-ubyte\"])\n",
    "test_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-labels.idx1-ubyte\"])\n",
    "\n",
    "def read_images_labels(images_filepath, labels_filepath) -> tuple:\n",
    "    labels = []\n",
    "    with open(labels_filepath, 'rb') as file:\n",
    "        magic, size = struct.unpack(\">II\", file.read(8))\n",
    "        if magic != 2049:\n",
    "            raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "        # labels = array(\"B\", file.read())\n",
    "        labels = array(\"B\", file.read())\n",
    "\n",
    "    with open(images_filepath, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "        image_data = array(\"B\", file.read())       \n",
    "     \n",
    "    images = []\n",
    "    # for i in range(size):\n",
    "    #     images.append([0] * rows * cols)\n",
    "    for i in range(size):\n",
    "        img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "        img = img.reshape(28, 28)\n",
    "        # images[i][:] = img\n",
    "        images.append(img)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def load_data() -> tuple:\n",
    "    x_train, y_train = read_images_labels(training_images_filepath, training_labels_filepath)\n",
    "    x_test, y_test = read_images_labels(test_images_filepath, test_labels_filepath)\n",
    "    return (x_train, y_train),(x_test, y_test)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Print train data:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:16:10.460151Z",
     "start_time": "2024-08-12T15:16:10.385180Z"
    }
   },
   "source": [
    "# print(f\"{type(X_train[0])}\")\n",
    "# mnist = tf.keras.datasets.mnist\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Convert data from [0, 255] &rarr; [0, 1]"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:19:36.894127Z",
     "start_time": "2024-08-12T15:19:36.788245Z"
    }
   },
   "source": [
    "X_train = np.asarray(X_train)/255\n",
    "y_train = np.asarray(y_train)\n",
    "X_test  = np.asarray(X_test)/255\n",
    "y_test  = np.asarray(y_test)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "4. Create NN:\n",
    "- Create Flatter layer to flat from $28 \\times 28 = 784$ to a vector\n",
    "- Create 1st Hidden layer, 32 units, activation is *ReLU*\n",
    "- Create 2nd Hidden layer, 10 units, activation is *Linear*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:23:51.219177Z",
     "start_time": "2024-08-12T15:23:51.186073Z"
    }
   },
   "source": [
    "model = tf.keras.models.Sequential(layers=[\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28,)),\n",
    "    tf.keras.layers.Dense(units=32, activation=tf.keras.activations.relu),\n",
    "    # tf.keras.layers.Dense(units=128, activation=tf.keras.activations.hard_sigmoid),\n",
    "    # tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=10, activation=tf.keras.activations.linear)\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# predictions = model(X_train[0]).numpy()\n",
    "# predictions\n",
    "# tf.nn.softmax(predictions).numpy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "#               metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.FalseNegatives()])\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "              loss=loss_fn,\n",
    "              metrics=[\"accuracy\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# X_train, X_test = np.asarray(X_train) / 255.0, np.asarray(X_test) / 255.0\n",
    "# print(X_test)\n",
    "model.fit(x=X_train, y=y_train, epochs=2, batch_size=600, workers=8, use_multiprocessing=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)\n",
    "c = 0\n",
    "cp = 0\n",
    "for i in range(100):\n",
    "    test_indx = rd.randint(0, len(y_test)-1)\n",
    "    x_test_ = np.asarray([X_test[test_indx]])\n",
    "\n",
    "    # test_indx = rd.randint(0, len(y_train)-1)\n",
    "    # x_test_ = np.asarray([X_train[test_indx]])\n",
    "\n",
    "    result = model.predict(x=x_test_, verbose=0)\n",
    "    result = tf.nn.softmax(result).numpy()\n",
    "    y_test_ = y_test\n",
    "    if result.max() >= 0.5:\n",
    "        if result.argmax() != y_test_[test_indx]:\n",
    "            c+=1\n",
    "            print(f\"- [{i}]:img[{test_indx}]:{result}\\npred:{result.max()}\\npredict:{result.argmax()} solve:{y_test_[test_indx]}\")\n",
    "    else:\n",
    "        print(f\"can not predict:{cp}: {result.max()}\")\n",
    "        cp+=1\n",
    "print(f\"error: {c} can not pred:{cp}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def show_image(img_data: np.ndarray) -> tuple:\n",
    "    fig, axes = plt.subplots(figsize=(1.60, 1.20))\n",
    "    axes.imshow(X=img_data, cmap=\"gray\")\n",
    "    return fig, axes\n",
    "\n",
    "# print(y_test[5854])\n",
    "show_image(X_test[381])\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
    "# tf.config.experimental_connect_to_cluster(resolver)\n",
    "# # This is the TPU initialization code that has to be at the beginning.\n",
    "# tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "# print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
