{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:08:16.664399Z",
     "start_time": "2024-08-13T14:08:14.935298Z"
    }
   },
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "import random as rd\n",
    "\n",
    "from array import array\n",
    "# import keras._tf_keras.keras as keras \n",
    "# from keras._tf_keras.keras\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# my project\n",
    "from module.conf import PROJECT_DIR\n",
    "\n",
    "# matplotlib.use(\"QTAgg\")\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data:\n",
    "- Train data: 60k 28x28 images\n",
    "- Test data: "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:08:18.454465Z",
     "start_time": "2024-08-13T14:08:18.313274Z"
    }
   },
   "source": [
    "mnist_path = \"/data/sample/mnist\"\n",
    "training_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-images.idx3-ubyte\"])\n",
    "training_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-labels.idx1-ubyte\"])\n",
    "test_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-images.idx3-ubyte\"])\n",
    "test_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-labels.idx1-ubyte\"])\n",
    "\n",
    "def read_images_labels(images_filepath, labels_filepath) -> tuple:\n",
    "    labels = []\n",
    "    with open(labels_filepath, 'rb') as file:\n",
    "        magic, size = struct.unpack(\">II\", file.read(8))\n",
    "        if magic != 2049:\n",
    "            raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "        # labels = array(\"B\", file.read())\n",
    "        labels = array(\"B\", file.read())\n",
    "\n",
    "    with open(images_filepath, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "        image_data = array(\"B\", file.read())       \n",
    "     \n",
    "    images = []\n",
    "    # for i in range(size):\n",
    "    #     images.append([0] * rows * cols)\n",
    "    for i in range(size):\n",
    "        img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "        img = img.reshape(28, 28)\n",
    "        # images[i][:] = img\n",
    "        images.append(img)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def load_data() -> tuple:\n",
    "    x_train, y_train = read_images_labels(training_images_filepath, training_labels_filepath)\n",
    "    x_test, y_test = read_images_labels(test_images_filepath, test_labels_filepath)\n",
    "    return (x_train, y_train),(x_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:08:20.550765Z",
     "start_time": "2024-08-13T14:08:20.547585Z"
    }
   },
   "source": [
    "# print(f\"{type(X_train[0])}\")\n",
    "# mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T17:38:50.335217Z",
     "start_time": "2024-08-13T17:38:01.764516Z"
    }
   },
   "source": [
    "X_train = np.asarray(X_train)/255\n",
    "y_train = np.asarray(y_train)\n",
    "X_test  = np.asarray(X_test)/255\n",
    "y_test  = np.asarray(y_test)"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[111], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m y_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(y_train)\n\u001B[1;32m      3\u001B[0m X_test  \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(X_test)\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m255\u001B[39m\n\u001B[0;32m----> 4\u001B[0m y_test  \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39masarray(y_test)\n",
      "Cell \u001B[0;32mIn[111], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m y_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(y_train)\n\u001B[1;32m      3\u001B[0m X_test  \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(X_test)\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m255\u001B[39m\n\u001B[0;32m----> 4\u001B[0m y_test  \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39masarray(y_test)\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_310_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_310_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Applications/PyCharm Professional Edition.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1207\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1204\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1206\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1207\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Applications/PyCharm Professional Edition.app/Contents/plugins/python-ce/helpers/pydev/pydevd.py:1222\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1219\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1221\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1222\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1224\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1226\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:33:42.180511Z",
     "start_time": "2024-08-13T16:33:42.149124Z"
    }
   },
   "source": [
    "model = tf.keras.models.Sequential(layers=[\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28,)),\n",
    "    tf.keras.layers.Dense(units=32, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(units=128, activation=tf.keras.activations.hard_sigmoid),\n",
    "    # tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=10, activation=tf.keras.activations.softmax)\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:33:42.668504Z",
     "start_time": "2024-08-13T16:33:42.659557Z"
    }
   },
   "source": [
    "# predictions = model(X_train[0]).numpy()\n",
    "# predictions\n",
    "# tf.nn.softmax(predictions).numpy()\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                25120     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,634\n",
      "Trainable params: 30,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:33:44.054649Z",
     "start_time": "2024-08-13T16:33:44.031814Z"
    }
   },
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "# loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# loss_fn = tf.keras.losses.CategoricalHinge()\n",
    "# loss_fn = tf.keras.losses.MeanSquaredLogarithmicError()\n",
    "# model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "#               metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.FalseNegatives()])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=loss_fn,\n",
    "              metrics=[\"accuracy\"])"
   ],
   "outputs": [],
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:34:10.676511Z",
     "start_time": "2024-08-13T16:33:59.926162Z"
    }
   },
   "source": [
    "# X_train, X_test = np.asarray(X_train) / 255.0, np.asarray(X_test) / 255.0\n",
    "# print(X_test)\n",
    "model.fit(x=X_train, y=y_train, epochs=50, batch_size=600, workers=8, use_multiprocessing=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3226 - accuracy: 0.9109\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.9222\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.9298\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2220 - accuracy: 0.9358\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9422\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9484\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1644 - accuracy: 0.9527\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9558\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9584\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1311 - accuracy: 0.9615\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9635\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.9661\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9677\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9692\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9709\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.9722\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9743\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.9752\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9760\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0782 - accuracy: 0.9772\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9783\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.9789\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9798\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9805\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9815\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9818\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9827\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9827\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9837\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9846\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9851\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9855\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9864\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9867\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9874\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9870\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9884\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9885\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9891\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9896\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9902\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9902\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9908\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9914\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9915\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9922\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9924\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9926\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9931\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x347b00f10>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 109
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:34:18.369114Z",
     "start_time": "2024-08-13T16:34:16.630804Z"
    }
   },
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)\n",
    "c = 0\n",
    "cp = 0\n",
    "for i in range(100):\n",
    "    test_indx = rd.randint(0, len(y_test)-1)\n",
    "    x_test_ = np.asarray([X_test[test_indx]])\n",
    "\n",
    "    # test_indx = rd.randint(0, len(y_train)-1)\n",
    "    # x_test_ = np.asarray([X_train[test_indx]])\n",
    "\n",
    "    result = model.predict(x=x_test_, verbose=0)\n",
    "    # result = tf.nn.softmax(result).numpy()\n",
    "    y_test_ = y_test\n",
    "    # if result.max() >= 0.5:\n",
    "    if result.argmax() != y_test_[test_indx]:\n",
    "        c+=1\n",
    "        print(f\"- [{i}]:img[{test_indx}]:{result}\\npred:{result.max()}\\npredict:{result.argmax()} solve:{y_test_[test_indx]}\")\n",
    "    else:\n",
    "        print(f\"+ [{i}]:img[{test_indx}]:{result}\\npred:{result.max()}\\npredict:{result.argmax()} solve:{y_test_[test_indx]}\")\n",
    "    # else:\n",
    "    #     print(f\"= [{i}]:img[{test_indx}]:{result}\\npred:{result.max()}\\npredict:{result.argmax()} solve:{y_test_[test_indx]}\")\n",
    "    #     cp+=1\n",
    "print(f\"error: {c} can not pred:{cp}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0964 - accuracy: 0.9735 - 166ms/epoch - 530us/step\n",
      "+ [0]:img[5850]:[[2.7108197e-06 1.9385432e-05 3.6754348e-06 9.9989188e-01 3.7129229e-08\n",
      "  2.2058550e-06 1.1915336e-09 2.0540094e-08 2.9353145e-05 5.0714883e-05]]\n",
      "pred:0.9998918771743774\n",
      "predict:3 solve:3\n",
      "+ [1]:img[9018]:[[1.5838665e-07 3.7183793e-04 9.9794537e-01 9.5586547e-05 1.3206399e-06\n",
      "  4.7588534e-07 5.2331888e-08 1.5850893e-03 1.0511897e-07 1.4557484e-11]]\n",
      "pred:0.9979453682899475\n",
      "predict:2 solve:2\n",
      "+ [2]:img[7398]:[[9.1261285e-08 3.8208946e-06 2.7474965e-07 9.9979991e-01 1.4592685e-08\n",
      "  9.1561869e-06 2.2514375e-12 7.6135976e-08 1.5103265e-04 3.5562574e-05]]\n",
      "pred:0.999799907207489\n",
      "predict:3 solve:3\n",
      "+ [3]:img[1794]:[[9.8625988e-01 1.0706133e-03 7.3504318e-03 1.2445984e-05 1.3696276e-05\n",
      "  6.4442342e-05 5.1994501e-03 6.8464501e-06 2.7109304e-06 1.9488734e-05]]\n",
      "pred:0.9862598776817322\n",
      "predict:0 solve:0\n",
      "+ [4]:img[2608]:[[2.6827936e-07 8.3336505e-05 2.0077766e-06 8.2578708e-06 1.9815013e-06\n",
      "  9.3720664e-06 2.2287186e-06 1.8586924e-07 9.9987602e-01 1.6288004e-05]]\n",
      "pred:0.9998760223388672\n",
      "predict:8 solve:8\n",
      "+ [5]:img[1953]:[[8.0110311e-08 6.0282096e-06 1.5989031e-08 9.9992716e-01 5.4278053e-09\n",
      "  3.9860170e-05 5.1251769e-10 3.0095737e-08 5.2834275e-06 2.1505430e-05]]\n",
      "pred:0.9999271631240845\n",
      "predict:3 solve:3\n",
      "+ [6]:img[7106]:[[7.49613150e-07 1.08143366e-04 5.08733999e-10 6.39339632e-05\n",
      "  1.04403523e-04 4.29822376e-06 4.77143089e-08 1.80106392e-04\n",
      "  6.68069115e-05 9.99471486e-01]]\n",
      "pred:0.9994714856147766\n",
      "predict:9 solve:9\n",
      "+ [7]:img[1889]:[[9.47140233e-09 2.23166659e-04 2.42333736e-05 9.99580562e-01\n",
      "  2.42097506e-08 1.59034826e-04 2.23502394e-09 8.55971916e-09\n",
      "  1.28563715e-05 1.41015519e-07]]\n",
      "pred:0.9995805621147156\n",
      "predict:3 solve:3\n",
      "+ [8]:img[483]:[[8.8095607e-05 3.0342417e-05 8.2265444e-08 8.3165060e-07 2.7841363e-06\n",
      "  9.9679476e-01 1.7590418e-06 3.0480297e-03 2.7550625e-05 5.8228716e-06]]\n",
      "pred:0.9967947602272034\n",
      "predict:5 solve:5\n",
      "+ [9]:img[6942]:[[6.9544662e-08 2.8421235e-08 2.8298268e-09 1.8489176e-05 4.5034648e-10\n",
      "  9.9987018e-01 4.5080416e-08 8.5063900e-11 1.0776267e-04 3.3116435e-06]]\n",
      "pred:0.9998701810836792\n",
      "predict:5 solve:5\n",
      "+ [10]:img[221]:[[4.9569079e-04 4.1266668e-07 9.9896181e-01 2.8474629e-04 2.0173943e-06\n",
      "  3.1317195e-06 6.1382434e-06 1.3151395e-04 1.1448686e-04 1.3189093e-07]]\n",
      "pred:0.9989618062973022\n",
      "predict:2 solve:2\n",
      "+ [11]:img[4465]:[[5.4837255e-07 1.6256570e-05 1.0092880e-04 1.0000850e-06 9.9984872e-01\n",
      "  2.7705662e-06 3.6419169e-06 1.8229950e-05 2.6105017e-08 7.7459108e-06]]\n",
      "pred:0.9998487234115601\n",
      "predict:4 solve:4\n",
      "+ [12]:img[6348]:[[1.8739829e-06 4.0789669e-08 1.2583451e-04 3.1605796e-07 1.4860391e-08\n",
      "  1.7671346e-05 2.2092163e-06 1.3980717e-09 9.9983239e-01 1.9710653e-05]]\n",
      "pred:0.9998323917388916\n",
      "predict:8 solve:8\n",
      "+ [13]:img[5706]:[[3.3646808e-07 4.6112852e-08 6.0849201e-09 2.4577153e-08 1.3227893e-08\n",
      "  9.9990427e-01 2.4127503e-06 1.1523932e-09 9.2792019e-05 5.8981712e-08]]\n",
      "pred:0.9999042749404907\n",
      "predict:5 solve:5\n",
      "+ [14]:img[7923]:[[7.6716560e-07 2.7905974e-08 4.8673483e-06 3.7329823e-06 9.4881756e-09\n",
      "  1.7211041e-06 8.8413499e-10 3.6306673e-08 9.9998796e-01 8.3031262e-07]]\n",
      "pred:0.9999879598617554\n",
      "predict:8 solve:8\n",
      "+ [15]:img[2894]:[[9.9697959e-01 3.9995534e-06 1.8802267e-06 1.4321105e-07 2.8769457e-06\n",
      "  3.2913125e-05 2.9013844e-03 2.1512383e-06 1.3812447e-05 6.1347717e-05]]\n",
      "pred:0.9969795942306519\n",
      "predict:0 solve:0\n",
      "+ [16]:img[6149]:[[2.6070188e-07 5.8869091e-07 2.0634843e-07 1.7184080e-05 3.8291414e-08\n",
      "  3.0535393e-08 3.1557982e-11 9.9941742e-01 8.8230690e-06 5.5541191e-04]]\n",
      "pred:0.9994174242019653\n",
      "predict:7 solve:7\n",
      "+ [17]:img[2936]:[[3.3793555e-09 1.1012914e-07 3.7455141e-07 1.1097318e-06 9.9949098e-01\n",
      "  5.1394892e-07 7.0744712e-09 1.5315896e-07 1.0488908e-06 5.0568936e-04]]\n",
      "pred:0.9994909763336182\n",
      "predict:4 solve:4\n",
      "+ [18]:img[4678]:[[1.1734032e-07 3.8802767e-07 5.2204581e-07 8.1763966e-07 7.5282308e-08\n",
      "  7.3208120e-08 7.7311222e-12 9.9995303e-01 8.1853218e-09 4.5007582e-05]]\n",
      "pred:0.999953031539917\n",
      "predict:7 solve:7\n",
      "+ [19]:img[8024]:[[2.7058444e-08 6.8808667e-08 4.4819679e-08 3.8554008e-12 3.8658359e-06\n",
      "  2.2556342e-06 9.9999380e-01 2.1513300e-11 3.1506808e-08 4.9493898e-10]]\n",
      "pred:0.9999938011169434\n",
      "predict:6 solve:6\n",
      "+ [20]:img[2535]:[[2.8935660e-06 6.6410472e-08 3.3658415e-07 4.0283865e-10 7.7496570e-06\n",
      "  5.5023013e-09 9.9998415e-01 2.7808181e-10 4.7598451e-06 1.3050435e-08]]\n",
      "pred:0.9999841451644897\n",
      "predict:6 solve:6\n",
      "+ [21]:img[4038]:[[8.3749420e-08 9.8832716e-05 9.9981529e-01 7.6699580e-05 1.2423251e-10\n",
      "  1.1353319e-07 8.3686151e-09 2.9730452e-07 8.7031658e-06 8.4651580e-10]]\n",
      "pred:0.9998152852058411\n",
      "predict:2 solve:2\n",
      "+ [22]:img[6855]:[[2.2517382e-07 3.1923362e-09 9.2233350e-09 8.5667295e-09 2.2155517e-09\n",
      "  3.7881125e-07 1.2464872e-12 9.9996424e-01 3.6110401e-10 3.5197510e-05]]\n",
      "pred:0.9999642372131348\n",
      "predict:7 solve:7\n",
      "+ [23]:img[564]:[[9.9991369e-01 9.9581001e-09 2.8006477e-07 1.8120733e-09 4.1765539e-08\n",
      "  3.8486751e-06 7.5089883e-05 1.3807337e-06 4.3876585e-07 5.2707901e-06]]\n",
      "pred:0.9999136924743652\n",
      "predict:0 solve:0\n",
      "+ [24]:img[1763]:[[1.2460561e-07 2.6362195e-06 1.5307142e-08 9.9947280e-01 5.8694162e-08\n",
      "  9.6562580e-05 6.6767913e-10 1.2708814e-06 1.9225081e-05 4.0726404e-04]]\n",
      "pred:0.9994727969169617\n",
      "predict:3 solve:3\n",
      "+ [25]:img[6863]:[[8.8511082e-10 6.1997440e-07 1.6628181e-07 9.9999809e-01 8.8973501e-10\n",
      "  5.8699004e-07 4.2937503e-12 5.7311902e-09 5.1220013e-07 1.3065691e-07]]\n",
      "pred:0.9999980926513672\n",
      "predict:3 solve:3\n",
      "+ [26]:img[6743]:[[1.4931734e-07 9.9973840e-01 7.3177296e-05 1.0266864e-07 1.3604468e-06\n",
      "  6.0866090e-11 2.6333062e-08 1.8567548e-04 9.9745739e-07 1.1239978e-07]]\n",
      "pred:0.9997383952140808\n",
      "predict:1 solve:1\n",
      "+ [27]:img[5606]:[[2.6389191e-09 4.6051468e-08 6.1381087e-08 9.9998748e-01 2.9702214e-09\n",
      "  4.8986162e-06 1.6521155e-12 2.4011701e-08 5.7820957e-06 1.6015024e-06]]\n",
      "pred:0.9999874830245972\n",
      "predict:3 solve:3\n",
      "+ [28]:img[5849]:[[8.5467997e-09 2.1416963e-05 9.9997735e-01 3.0042690e-07 1.3947477e-09\n",
      "  5.9250413e-09 4.4086041e-09 9.0925214e-09 8.3339694e-07 8.3956531e-12]]\n",
      "pred:0.9999773502349854\n",
      "predict:2 solve:2\n",
      "+ [29]:img[8358]:[[1.5988265e-06 5.2144696e-07 4.8193733e-09 8.2221151e-05 1.3092728e-03\n",
      "  9.4586844e-04 4.4592494e-09 1.5855738e-03 3.3029635e-05 9.9604189e-01]]\n",
      "pred:0.9960418939590454\n",
      "predict:9 solve:9\n",
      "+ [30]:img[4389]:[[7.0864172e-07 7.5074888e-05 6.9430571e-06 7.9753035e-04 1.3459774e-07\n",
      "  3.4032179e-05 2.7295025e-07 9.3044866e-07 9.9905354e-01 3.0825722e-05]]\n",
      "pred:0.9990535378456116\n",
      "predict:8 solve:8\n",
      "+ [31]:img[4462]:[[9.9992704e-01 1.1108999e-08 5.1301828e-07 5.3297267e-10 1.8132740e-08\n",
      "  3.0403356e-07 6.8120455e-05 1.3453145e-07 1.7799114e-07 3.6289991e-06]]\n",
      "pred:0.9999270439147949\n",
      "predict:0 solve:0\n",
      "+ [32]:img[3706]:[[9.9921775e-01 1.3090206e-05 8.8153909e-05 2.3168063e-07 6.2742333e-07\n",
      "  4.4287444e-05 2.1978261e-05 2.8690614e-04 4.4234316e-06 3.2251480e-04]]\n",
      "pred:0.9992177486419678\n",
      "predict:0 solve:0\n",
      "+ [33]:img[1600]:[[7.0448755e-07 1.1185368e-06 6.1828223e-07 9.8005247e-01 1.9431388e-08\n",
      "  1.8928966e-02 5.2710136e-10 2.6283183e-07 1.2037067e-04 8.9562603e-04]]\n",
      "pred:0.9800524711608887\n",
      "predict:3 solve:3\n",
      "+ [34]:img[379]:[[2.3638776e-08 8.2877932e-08 1.1406361e-07 1.3798005e-08 9.9990630e-01\n",
      "  4.8629417e-08 9.4399280e-09 9.2712060e-07 2.0108372e-07 9.2308437e-05]]\n",
      "pred:0.9999063014984131\n",
      "predict:4 solve:4\n",
      "+ [35]:img[2089]:[[7.6065403e-09 8.4087264e-07 1.3187858e-10 2.3068980e-05 5.3339951e-05\n",
      "  1.6469189e-06 3.9493511e-10 3.2176834e-07 2.4495482e-06 9.9991822e-01]]\n",
      "pred:0.9999182224273682\n",
      "predict:9 solve:9\n",
      "+ [36]:img[5412]:[[1.2236617e-07 3.9122593e-08 3.6047524e-07 9.7653731e-07 2.6174134e-09\n",
      "  1.1825006e-08 6.1578141e-13 9.9998331e-01 6.5196637e-08 1.5165600e-05]]\n",
      "pred:0.9999833106994629\n",
      "predict:7 solve:7\n",
      "+ [37]:img[9326]:[[1.7448630e-06 7.5502513e-08 3.7174340e-07 3.3630022e-05 9.4499455e-08\n",
      "  1.0654834e-05 5.6456944e-08 9.1662976e-08 9.9991930e-01 3.3931690e-05]]\n",
      "pred:0.9999192953109741\n",
      "predict:8 solve:8\n",
      "+ [38]:img[6907]:[[2.94248714e-08 4.01056423e-05 1.69311897e-06 9.99932647e-01\n",
      "  1.06171356e-08 8.72923465e-06 1.54730586e-11 1.15234016e-07\n",
      "  1.34800111e-05 3.26076929e-06]]\n",
      "pred:0.9999326467514038\n",
      "predict:3 solve:3\n",
      "+ [39]:img[6568]:[[1.6211807e-06 1.3334732e-04 3.7069331e-06 5.2065728e-04 2.9980683e-01\n",
      "  1.6018497e-02 6.3963321e-06 3.4610941e-05 2.5724850e-04 6.8321699e-01]]\n",
      "pred:0.6832169890403748\n",
      "predict:9 solve:9\n",
      "+ [40]:img[6913]:[[1.10161675e-08 9.99941111e-01 7.54020846e-07 5.91061416e-06\n",
      "  1.94730128e-05 2.74350747e-08 2.17560250e-06 6.25455641e-06\n",
      "  2.16260869e-05 2.70510850e-06]]\n",
      "pred:0.9999411106109619\n",
      "predict:1 solve:1\n",
      "+ [41]:img[2344]:[[2.5975179e-08 5.5662440e-06 2.5593539e-07 1.0076460e-06 9.0576208e-08\n",
      "  2.0606163e-10 5.6948799e-12 9.9998581e-01 1.7024350e-08 7.2722928e-06]]\n",
      "pred:0.9999858140945435\n",
      "predict:7 solve:7\n",
      "+ [42]:img[6420]:[[1.9724537e-07 1.7954490e-06 4.5222243e-10 2.1642983e-04 1.1788394e-04\n",
      "  6.0142333e-06 2.2349295e-07 4.9989939e-07 1.6637739e-05 9.9964023e-01]]\n",
      "pred:0.9996402263641357\n",
      "predict:9 solve:9\n",
      "+ [43]:img[7571]:[[1.4484013e-06 9.5888952e-10 4.9828701e-09 6.1762159e-07 5.9483562e-05\n",
      "  3.3409506e-07 4.0662953e-09 1.8546487e-05 3.3590220e-06 9.9991620e-01]]\n",
      "pred:0.9999161958694458\n",
      "predict:9 solve:9\n",
      "- [44]:img[9808]:[[3.7527320e-04 4.3164422e-05 1.4965008e-06 2.1655567e-04 2.1061884e-01\n",
      "  1.9587951e-05 3.4518098e-07 4.2544046e-01 8.8622010e-06 3.6327541e-01]]\n",
      "pred:0.4254404604434967\n",
      "predict:7 solve:9\n",
      "+ [45]:img[9258]:[[8.6236058e-09 9.9994779e-01 2.3552268e-06 1.6328427e-09 5.5453215e-06\n",
      "  4.1507207e-11 5.8439703e-08 4.3828823e-05 3.6543528e-07 1.6142968e-09]]\n",
      "pred:0.9999477863311768\n",
      "predict:1 solve:1\n",
      "+ [46]:img[3648]:[[2.5237606e-10 9.9997008e-01 8.1224357e-07 3.5449122e-07 1.9204247e-06\n",
      "  1.9507367e-09 7.9020474e-08 2.5756259e-05 7.6150781e-07 1.9481784e-07]]\n",
      "pred:0.9999700784683228\n",
      "predict:1 solve:1\n",
      "+ [47]:img[6412]:[[3.5996973e-06 1.5815031e-07 9.9998331e-01 2.0666355e-06 8.2861673e-09\n",
      "  3.5022057e-07 9.3473191e-06 5.8289821e-08 1.0259781e-06 2.8291458e-11]]\n",
      "pred:0.9999833106994629\n",
      "predict:2 solve:2\n",
      "+ [48]:img[3392]:[[5.5391233e-08 1.9092860e-07 1.4686057e-09 9.4919977e-07 1.0431276e-04\n",
      "  1.4319957e-03 3.1436389e-07 3.2495558e-07 1.8358187e-05 9.9844354e-01]]\n",
      "pred:0.9984435439109802\n",
      "predict:9 solve:9\n",
      "- [49]:img[2044]:[[1.9553856e-06 4.2238207e-07 1.4191541e-01 1.5743211e-04 1.6258062e-08\n",
      "  6.9655198e-06 3.2159353e-10 8.5772246e-01 1.8888104e-04 6.3844941e-06]]\n",
      "pred:0.8577224612236023\n",
      "predict:7 solve:2\n",
      "+ [50]:img[4107]:[[2.4957252e-08 6.8575046e-06 7.9200236e-06 8.4718613e-06 3.5638283e-09\n",
      "  1.1729522e-10 1.0767517e-10 9.9997544e-01 6.6206653e-08 1.2171944e-06]]\n",
      "pred:0.9999754428863525\n",
      "predict:7 solve:7\n",
      "+ [51]:img[9061]:[[3.9440775e-09 9.9948186e-01 1.2237208e-06 1.1268640e-04 1.8538414e-05\n",
      "  2.7698152e-07 3.7645977e-06 3.4302723e-06 3.7642999e-04 1.8268058e-06]]\n",
      "pred:0.9994818568229675\n",
      "predict:1 solve:1\n",
      "+ [52]:img[4506]:[[3.2544328e-04 7.5177593e-07 9.9938762e-01 7.6292905e-05 1.6728483e-08\n",
      "  2.3446050e-08 2.5036575e-08 1.5521988e-05 1.9329341e-04 1.0561969e-06]]\n",
      "pred:0.9993876218795776\n",
      "predict:2 solve:2\n",
      "+ [53]:img[7193]:[[6.81620691e-07 1.15714065e-04 3.47865338e-04 9.99519348e-01\n",
      "  2.09392348e-09 2.94367055e-06 3.35688782e-10 8.12306169e-08\n",
      "  8.86142880e-06 4.30988575e-06]]\n",
      "pred:0.9995193481445312\n",
      "predict:3 solve:3\n",
      "+ [54]:img[3564]:[[2.3618755e-05 5.2276982e-06 3.5539531e-07 8.4412825e-08 1.3586205e-05\n",
      "  1.0050145e-05 9.9966776e-01 3.0389553e-09 2.7932820e-04 1.7590349e-08]]\n",
      "pred:0.999667763710022\n",
      "predict:6 solve:6\n",
      "+ [55]:img[5927]:[[3.2214892e-08 3.7322415e-08 5.0932925e-07 4.3646873e-09 9.9999070e-01\n",
      "  3.5058039e-07 2.1015421e-07 1.0945146e-08 6.7077946e-07 7.5165412e-06]]\n",
      "pred:0.999990701675415\n",
      "predict:4 solve:4\n",
      "+ [56]:img[3105]:[[4.7760100e-08 2.3105786e-06 9.9999571e-01 8.5999142e-07 7.1750486e-07\n",
      "  2.4973510e-09 3.5516285e-07 1.3579758e-08 5.9595404e-08 3.3048460e-12]]\n",
      "pred:0.9999957084655762\n",
      "predict:2 solve:2\n",
      "+ [57]:img[8351]:[[9.9988699e-01 4.1362202e-07 4.2315773e-06 8.3623615e-07 8.2868547e-07\n",
      "  2.0969594e-06 1.5112953e-06 4.1074272e-05 4.1544055e-07 6.1553386e-05]]\n",
      "pred:0.9998869895935059\n",
      "predict:0 solve:0\n",
      "+ [58]:img[5012]:[[1.45139381e-06 7.14854968e-06 1.20289615e-05 4.58678963e-11\n",
      "  3.44477266e-05 1.54994151e-08 9.99944925e-01 1.36303431e-08\n",
      "  1.10137091e-08 5.59302549e-10]]\n",
      "pred:0.9999449253082275\n",
      "predict:6 solve:6\n",
      "+ [59]:img[6309]:[[9.9994862e-01 4.7984139e-07 5.5159107e-06 2.0493975e-09 5.9468577e-09\n",
      "  2.5371169e-06 2.6021944e-06 3.8949864e-05 4.0494456e-07 8.6585788e-07]]\n",
      "pred:0.9999486207962036\n",
      "predict:0 solve:0\n",
      "+ [60]:img[638]:[[2.4825699e-06 3.3597610e-07 6.7101689e-09 1.1564566e-05 7.1063596e-08\n",
      "  9.9906141e-01 7.9747879e-09 9.0034964e-04 1.8819790e-05 4.9475116e-06]]\n",
      "pred:0.9990614056587219\n",
      "predict:5 solve:5\n",
      "- [61]:img[2953]:[[5.5836001e-05 1.3152060e-04 2.6102483e-05 8.7132446e-02 3.9226397e-06\n",
      "  8.8827574e-01 3.5421201e-06 3.7403275e-05 8.7356567e-03 1.5597850e-02]]\n",
      "pred:0.8882757425308228\n",
      "predict:5 solve:3\n",
      "+ [62]:img[2844]:[[4.4540527e-09 1.6722805e-06 4.3556736e-07 2.4171932e-06 3.1405307e-09\n",
      "  4.2901533e-11 7.7326519e-13 9.9999487e-01 1.1604278e-08 5.5518399e-07]]\n",
      "pred:0.9999948740005493\n",
      "predict:7 solve:7\n",
      "+ [63]:img[2539]:[[3.9251623e-07 3.8362168e-06 5.1309464e-05 1.2233553e-03 5.3549726e-08\n",
      "  2.0630303e-08 1.5547037e-09 9.9868637e-01 3.3296462e-06 3.1287262e-05]]\n",
      "pred:0.9986863732337952\n",
      "predict:7 solve:7\n",
      "+ [64]:img[7265]:[[7.49618948e-07 2.31822703e-08 2.16302101e-06 5.76854357e-03\n",
      "  7.68277553e-10 6.67921677e-06 1.53060042e-09 1.03379996e-07\n",
      "  9.94199276e-01 2.24986943e-05]]\n",
      "pred:0.994199275970459\n",
      "predict:8 solve:8\n",
      "+ [65]:img[3380]:[[3.1517825e-08 9.9989331e-01 2.1065605e-05 1.2555747e-06 1.5705848e-05\n",
      "  2.0819688e-09 1.4974914e-06 6.1320228e-05 4.3734221e-06 1.4201768e-06]]\n",
      "pred:0.999893307685852\n",
      "predict:1 solve:1\n",
      "+ [66]:img[8228]:[[9.9980313e-01 4.8543063e-07 1.7384546e-05 3.6448415e-05 5.1768533e-05\n",
      "  1.0312735e-06 5.0794068e-05 3.4651195e-05 7.8499687e-07 3.4777313e-06]]\n",
      "pred:0.9998031258583069\n",
      "predict:0 solve:0\n",
      "- [67]:img[1522]:[[3.1676780e-07 2.8651982e-04 1.2756452e-05 9.9198463e-05 1.5481237e-04\n",
      "  1.1338489e-02 2.0789607e-06 1.1270489e-03 3.3602603e-03 9.8361856e-01]]\n",
      "pred:0.9836185574531555\n",
      "predict:9 solve:7\n",
      "+ [68]:img[1871]:[[1.18803755e-05 1.27283274e-03 9.77937043e-01 5.11324266e-04\n",
      "  3.26550378e-07 1.77886488e-06 1.05711354e-06 1.95107859e-05\n",
      "  2.02441737e-02 1.76074209e-07]]\n",
      "pred:0.9779370427131653\n",
      "predict:2 solve:2\n",
      "+ [69]:img[6380]:[[1.8501862e-06 7.2855343e-08 7.6415080e-07 6.8728497e-07 9.5217478e-10\n",
      "  2.7520802e-08 2.1923852e-11 9.9992716e-01 6.0603622e-10 6.9518494e-05]]\n",
      "pred:0.9999271631240845\n",
      "predict:7 solve:7\n",
      "+ [70]:img[2613]:[[1.9454827e-09 3.0186889e-08 4.8780795e-08 8.9309971e-08 9.9999309e-01\n",
      "  6.8039540e-08 5.6613887e-09 3.8167958e-08 3.6625360e-07 6.2167551e-06]]\n",
      "pred:0.999993085861206\n",
      "predict:4 solve:4\n",
      "+ [71]:img[6129]:[[9.9979836e-01 1.5068876e-07 3.7429843e-05 7.9063094e-09 2.1052639e-07\n",
      "  4.0152549e-06 1.5058686e-04 2.5916327e-06 6.4114774e-06 2.4638254e-07]]\n",
      "pred:0.9997983574867249\n",
      "predict:0 solve:0\n",
      "+ [72]:img[2295]:[[9.9971253e-01 1.3648331e-07 6.4751097e-05 4.6167790e-09 3.4947521e-07\n",
      "  1.0392207e-05 2.0380873e-04 4.8519416e-07 4.1143953e-06 3.3434874e-06]]\n",
      "pred:0.9997125267982483\n",
      "predict:0 solve:0\n",
      "+ [73]:img[4973]:[[2.7650526e-11 8.5826940e-08 6.2996385e-08 9.9999833e-01 4.8124493e-10\n",
      "  1.0319958e-07 7.2710087e-14 1.5862403e-08 1.3268800e-06 1.5443817e-08]]\n",
      "pred:0.9999983310699463\n",
      "predict:3 solve:3\n",
      "+ [74]:img[6377]:[[8.4786066e-08 2.2945962e-05 3.5922525e-08 9.7821521e-07 1.0623247e-06\n",
      "  3.8670755e-08 1.8660931e-09 9.9909604e-01 5.9830808e-07 8.7825157e-04]]\n",
      "pred:0.9990960359573364\n",
      "predict:7 solve:7\n",
      "+ [75]:img[9573]:[[6.4177613e-08 3.0944969e-07 1.7577113e-05 7.3591618e-05 6.1462644e-09\n",
      "  6.2297232e-08 1.0768014e-12 9.9989295e-01 1.1120982e-06 1.4410992e-05]]\n",
      "pred:0.9998929500579834\n",
      "predict:7 solve:7\n",
      "+ [76]:img[9747]:[[1.4824013e-03 5.6197567e-09 2.1353699e-07 3.0973599e-05 3.2379342e-06\n",
      "  9.9837756e-01 1.3083055e-05 1.7294667e-07 2.2158104e-06 9.0184018e-05]]\n",
      "pred:0.9983775615692139\n",
      "predict:5 solve:5\n",
      "+ [77]:img[7969]:[[1.0852171e-07 9.9994695e-01 6.9765042e-06 7.7539184e-09 5.0181925e-06\n",
      "  7.6304003e-09 4.5750849e-06 3.0688832e-05 5.5558721e-06 1.9602584e-07]]\n",
      "pred:0.9999469518661499\n",
      "predict:1 solve:1\n",
      "+ [78]:img[6736]:[[3.3776382e-09 6.2743062e-08 5.0987934e-09 9.9999535e-01 1.9734375e-10\n",
      "  2.6430646e-06 2.3015837e-13 1.6832269e-08 6.7095596e-07 1.2479941e-06]]\n",
      "pred:0.9999953508377075\n",
      "predict:3 solve:3\n",
      "+ [79]:img[187]:[[1.8865375e-08 1.1660851e-09 2.8062558e-08 3.3051074e-05 1.1527432e-10\n",
      "  9.9996054e-01 8.2483247e-09 1.1487836e-10 4.1123403e-06 2.1793683e-06]]\n",
      "pred:0.9999605417251587\n",
      "predict:5 solve:5\n",
      "+ [80]:img[6900]:[[1.3491551e-08 9.5431083e-08 1.4517725e-05 3.0646354e-11 3.2970465e-07\n",
      "  1.9010926e-09 9.9998498e-01 2.4549609e-09 1.9492081e-08 5.0715578e-11]]\n",
      "pred:0.9999849796295166\n",
      "predict:6 solve:6\n",
      "+ [81]:img[2127]:[[9.9984729e-01 2.2931210e-06 5.2352560e-05 1.3294265e-08 2.8245436e-08\n",
      "  1.7065927e-06 8.9723988e-05 5.8023020e-06 6.2244300e-07 7.7028709e-08]]\n",
      "pred:0.9998472929000854\n",
      "predict:0 solve:0\n",
      "+ [82]:img[1483]:[[8.11672118e-10 9.99738872e-01 2.37081917e-06 1.89666516e-05\n",
      "  1.19273855e-05 1.24475037e-06 2.21344362e-05 1.47009614e-05\n",
      "  1.88264385e-04 1.63821846e-06]]\n",
      "pred:0.999738872051239\n",
      "predict:1 solve:1\n",
      "+ [83]:img[8814]:[[2.8948577e-06 3.0085670e-07 5.0458139e-06 4.1898257e-08 2.7087319e-05\n",
      "  9.5920512e-08 9.9996400e-01 4.7257562e-09 6.4334125e-07 3.5509820e-10]]\n",
      "pred:0.9999639987945557\n",
      "predict:6 solve:6\n",
      "+ [84]:img[9683]:[[5.59361002e-09 1.46592868e-07 8.69451355e-08 2.09531379e-08\n",
      "  9.99995589e-01 2.58710067e-08 2.37426633e-07 2.17346906e-06\n",
      "  1.04756694e-07 1.67273777e-06]]\n",
      "pred:0.9999955892562866\n",
      "predict:4 solve:4\n",
      "+ [85]:img[1930]:[[5.0802043e-07 1.8667554e-06 9.9866033e-01 1.9596417e-05 1.3120557e-03\n",
      "  1.0741662e-06 4.0490318e-06 7.5518818e-09 4.4373337e-07 1.3466505e-09]]\n",
      "pred:0.9986603260040283\n",
      "predict:2 solve:2\n",
      "+ [86]:img[6110]:[[4.6262662e-06 9.9800080e-01 1.0833996e-05 6.4800120e-06 5.5536773e-05\n",
      "  1.4813993e-07 2.0232615e-05 4.3469470e-05 1.8516169e-03 6.2775048e-06]]\n",
      "pred:0.9980008006095886\n",
      "predict:1 solve:1\n",
      "+ [87]:img[1387]:[[9.0906394e-07 6.5537429e-06 6.0703758e-05 3.0195885e-10 1.9096705e-04\n",
      "  2.6771276e-09 9.9974078e-01 9.3420660e-08 8.5509075e-09 2.1176327e-09]]\n",
      "pred:0.9997407793998718\n",
      "predict:6 solve:6\n",
      "+ [88]:img[8748]:[[9.9998403e-01 2.0735586e-08 8.0411564e-06 9.5395876e-08 3.5254237e-09\n",
      "  1.8361577e-07 6.9284074e-06 4.8868941e-07 1.7014686e-07 6.1009239e-08]]\n",
      "pred:0.9999840259552002\n",
      "predict:0 solve:0\n",
      "+ [89]:img[591]:[[2.0166990e-05 3.0616790e-03 2.6376667e-03 1.1768491e-01 9.1859169e-05\n",
      "  2.5947122e-06 1.8243934e-04 1.2599676e-05 8.7630576e-01 3.6531139e-07]]\n",
      "pred:0.8763057589530945\n",
      "predict:8 solve:8\n",
      "+ [90]:img[5174]:[[1.9012903e-08 1.8109293e-06 3.1260644e-08 2.5900161e-05 2.1903899e-07\n",
      "  9.9989009e-01 5.5117515e-09 1.5702296e-08 7.7078279e-05 4.8577463e-06]]\n",
      "pred:0.9998900890350342\n",
      "predict:5 solve:5\n",
      "+ [91]:img[5978]:[[7.95509283e-11 9.99751747e-01 7.73645922e-07 1.04453815e-04\n",
      "  3.65169253e-05 6.06609956e-06 1.11530665e-06 3.23854806e-07\n",
      "  4.12708396e-05 5.78260988e-05]]\n",
      "pred:0.9997517466545105\n",
      "predict:1 solve:1\n",
      "+ [92]:img[7429]:[[5.2902669e-07 1.8908035e-07 5.9375252e-06 5.1850599e-09 9.9992716e-01\n",
      "  5.5009523e-06 4.5445654e-07 3.9296046e-05 1.4787670e-05 6.2358686e-06]]\n",
      "pred:0.9999271631240845\n",
      "predict:4 solve:4\n",
      "+ [93]:img[4303]:[[2.5751132e-07 9.9990356e-01 1.6949769e-05 9.0705630e-09 1.9702884e-05\n",
      "  3.6471985e-08 1.8120032e-05 2.7905684e-05 1.3490704e-05 1.4838288e-07]]\n",
      "pred:0.9999035596847534\n",
      "predict:1 solve:1\n",
      "+ [94]:img[5859]:[[8.4132312e-11 9.9999321e-01 1.7198104e-08 9.4928146e-07 1.8894206e-06\n",
      "  7.5069355e-09 1.4101228e-07 2.1392450e-06 8.8405920e-07 7.5418171e-07]]\n",
      "pred:0.9999932050704956\n",
      "predict:1 solve:1\n",
      "+ [95]:img[3169]:[[6.2858994e-09 1.5399941e-07 3.9277321e-08 4.1165532e-10 9.9998987e-01\n",
      "  1.1277334e-08 6.3398453e-08 1.3670025e-06 5.5070917e-08 8.5510856e-06]]\n",
      "pred:0.9999898672103882\n",
      "predict:4 solve:4\n",
      "+ [96]:img[4665]:[[6.7169963e-09 8.9734112e-06 3.6422986e-07 3.1546188e-05 1.0343341e-02\n",
      "  6.1923383e-05 5.3013731e-09 1.1305433e-06 9.6140961e-05 9.8945659e-01]]\n",
      "pred:0.9894565939903259\n",
      "predict:9 solve:9\n",
      "+ [97]:img[1423]:[[7.5705685e-07 2.4858804e-10 2.4670210e-09 2.2279943e-05 3.2291130e-06\n",
      "  7.6214070e-07 2.3246027e-10 2.4098175e-05 1.8723556e-05 9.9993014e-01]]\n",
      "pred:0.9999301433563232\n",
      "predict:9 solve:9\n",
      "+ [98]:img[1327]:[[1.0563269e-06 4.1150710e-08 1.3365396e-07 1.0283873e-04 7.8652716e-05\n",
      "  1.1431490e-06 9.8370521e-08 2.5669086e-05 9.1070578e-06 9.9978131e-01]]\n",
      "pred:0.9997813105583191\n",
      "predict:9 solve:9\n",
      "+ [99]:img[2289]:[[5.2026012e-06 3.3111778e-08 2.0198750e-04 3.2926167e-05 8.1398468e-08\n",
      "  7.4113796e-06 2.9734144e-07 2.8606598e-06 9.9974483e-01 4.3666928e-06]]\n",
      "pred:0.9997448325157166\n",
      "predict:8 solve:8\n",
      "error: 4 can not pred:0\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T16:33:48.610093Z",
     "start_time": "2024-08-13T16:33:48.572628Z"
    }
   },
   "source": [
    "def show_image(img_data: np.ndarray) -> tuple:\n",
    "    fig, axes = plt.subplots(figsize=(1.60, 1.20))\n",
    "    axes.imshow(X=img_data, cmap=\"gray\")\n",
    "    return fig, axes\n",
    "\n",
    "# print(y_test[5854])\n",
    "show_image(X_test[4823])\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 160x120 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:38:53.551921Z",
     "start_time": "2024-08-13T14:38:53.548354Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
    "# tf.config.experimental_connect_to_cluster(resolver)\n",
    "# # This is the TPU initialization code that has to be at the beginning.\n",
    "# tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "# print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Trong quá trình **backpropagation**, khi sử dụng hàm softmax trong lớp đầu ra của một mạng nơ-ron, ta cần tính toán gradient của hàm mất mát (thường là categorical cross-entropy) đối với các trọng số. Điều này yêu cầu tính toán đạo hàm của hàm softmax.\n",
    "\n",
    "### 1. **Hàm Softmax và Hàm Mất Mát Cross-Entropy**\n",
    "\n",
    "Giả sử đầu ra của mạng nơ-ron là một vector \\( \\mathbf{z} = [z_1, z_2, \\dots, z_n] \\). Hàm softmax được định nghĩa như sau:\n",
    "\n",
    "\\[\n",
    "\\sigma(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}}\n",
    "\\]\n",
    "\n",
    "Giả sử nhãn đúng là \\( y \\), hàm mất mát cross-entropy có dạng:\n",
    "\n",
    "\\[\n",
    "L = -\\sum_{i=1}^{n} y_i \\log(\\sigma(z_i))\n",
    "\\]\n",
    "\n",
    "### 2. **Đạo Hàm Của Hàm Mất Mát Đối Với Đầu Ra Của Softmax**\n",
    "\n",
    "Để thực hiện backpropagation, ta cần tính đạo hàm của hàm mất mát \\( L \\) đối với mỗi đầu ra của softmax \\( z_i \\):\n",
    "\n",
    "\\[\n",
    "\\frac{\\partial L}{\\partial z_i}\n",
    "\\]\n",
    "\n",
    "Sử dụng quy tắc dây chuyền, ta có:\n",
    "\n",
    "\\[\n",
    "\\frac{\\partial L}{\\partial z_i} = \\sum_{j=1}^{n} \\frac{\\partial L}{\\partial \\sigma(z_j)} \\cdot \\frac{\\partial \\sigma(z_j)}{\\partial z_i}\n",
    "\\]\n",
    "\n",
    "#### 2.1 **Đạo Hàm Của Hàm Mất Mát Với Softmax**\n",
    "\n",
    "Đạo hàm của hàm mất mát \\( L \\) đối với đầu ra của softmax \\( \\sigma(z_j) \\) là:\n",
    "\n",
    "\\[\n",
    "\\frac{\\partial L}{\\partial \\sigma(z_j)} = \\sigma(z_j) - y_j\n",
    "\\]\n",
    "\n",
    "#### 2.2 **Đạo Hàm Của Softmax**\n",
    "\n",
    "Đạo hàm của hàm softmax được tính như sau:\n",
    "\n",
    "\\[\n",
    "\\frac{\\partial \\sigma(z_j)}{\\partial z_i} = \n",
    "\\begin{cases} \n",
    "\\sigma(z_i) \\cdot (1 - \\sigma(z_i)) & \\text{nếu } i = j \\\\\n",
    "-\\sigma(z_i) \\cdot \\sigma(z_j) & \\text{nếu } i \\neq j \n",
    "\\end{cases}\n",
    "\\]\n",
    "\n",
    "### 3. **Vectorization (Tính Toán Dạng Vector)**\n",
    "\n",
    "Trong thực hành, tính toán đạo hàm của hàm softmax được thực hiện thông qua vectorization để tối ưu hóa hiệu suất. Giả sử \\( \\mathbf{\\sigma} \\) là vector chứa các giá trị softmax \\( \\sigma(z_1), \\sigma(z_2), \\dots, \\sigma(z_n) \\), ta có:\n",
    "\n",
    "\\[\n",
    "\\frac{\\partial \\mathbf{\\sigma}}{\\partial \\mathbf{z}} = \\text{Jacobian}(\\mathbf{\\sigma}) = \\mathbf{S} - \\mathbf{\\sigma} \\cdot \\mathbf{\\sigma}^T\n",
    "\\]\n",
    "\n",
    "trong đó:\n",
    "\n",
    "- \\( \\mathbf{S} \\) là ma trận chéo (diagonal matrix) với các phần tử \\( \\sigma(z_i) \\) trên đường chéo chính.\n",
    "- \\( \\mathbf{\\sigma} \\cdot \\mathbf{\\sigma}^T \\) là tích ngoài (outer product) của vector \\( \\mathbf{\\sigma} \\).\n",
    "\n",
    "Cụ thể hơn:\n",
    "\n",
    "\\[\n",
    "\\text{Jacobian}(\\mathbf{\\sigma}) = \\text{diag}(\\sigma) - \\sigma \\cdot \\sigma^T\n",
    "\\]\n",
    "\n",
    "### 4. **Gradient Đối Với Vector Đầu Ra**\n",
    "\n",
    "Cuối cùng, gradient của hàm mất mát đối với vector \\( \\mathbf{z} \\) (đầu ra trước softmax) có thể được biểu diễn dưới dạng vectorized:\n",
    "\n",
    "\\[\n",
    "\\frac{\\partial L}{\\partial \\mathbf{z}} = \\mathbf{\\sigma} - \\mathbf{y}\n",
    "\\]\n",
    "\n",
    "Đây là dạng vectorized của gradient, rất quan trọng trong quá trình huấn luyện mô hình với backpropagation vì nó cho phép tính toán gradient một cách hiệu quả, đặc biệt là khi làm việc với các tập dữ liệu lớn và các mô hình có nhiều lớp.\n",
    "\n",
    "### Tóm Lược\n",
    "\n",
    "- **Đạo hàm của hàm softmax** có thể được biểu diễn dưới dạng ma trận Jacobian.\n",
    "- Trong quá trình **backpropagation**, gradient của hàm mất mát đối với đầu ra trước softmax \\( z_i \\) có dạng vectorized: \\( \\frac{\\partial L}{\\partial \\mathbf{z}} = \\mathbf{\\sigma} - \\mathbf{y} \\).\n",
    "- Vectorization giúp tính toán gradient nhanh chóng và hiệu quả hơn khi huấn luyện các mô hình học sâu."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
