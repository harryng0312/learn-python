{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:41:56.150401Z",
     "start_time": "2024-09-24T15:41:56.145603Z"
    }
   },
   "source": [
    "import imp\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "import random as rd\n",
    "\n",
    "from math import *\n",
    "from array import array\n",
    "\n",
    "from keras.src.ops import shape\n",
    "# import keras._tf_keras.keras as keras \n",
    "# from keras._tf_keras.keras\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# my project\n",
    "from module.conf import PROJECT_DIR\n",
    "\n",
    "# matplotlib.use(\"QTAgg\")\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:\n",
    "- Train data: 60k 28x28 images\n",
    "- Test data: "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:42:02.136420Z",
     "start_time": "2024-09-24T15:42:02.021307Z"
    }
   },
   "source": [
    "mnist_path = \"/data/sample/mnist\"\n",
    "training_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-images.idx3-ubyte\"])\n",
    "training_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-labels.idx1-ubyte\"])\n",
    "test_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-images.idx3-ubyte\"])\n",
    "test_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-labels.idx1-ubyte\"])\n",
    "\n",
    "def read_images_labels(images_filepath, labels_filepath) -> tuple:\n",
    "    labels = []\n",
    "    with open(labels_filepath, 'rb') as file:\n",
    "        magic, size = struct.unpack(\">II\", file.read(8))\n",
    "        if magic != 2049:\n",
    "            raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "        # labels = array(\"B\", file.read())\n",
    "        labels = array(\"B\", file.read())\n",
    "\n",
    "    with open(images_filepath, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "        image_data = array(\"B\", file.read())       \n",
    "     \n",
    "    images = []\n",
    "    # for i in range(size):\n",
    "    #     images.append([0] * rows * cols)\n",
    "    for i in range(size):\n",
    "        img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "        img = img.reshape(28, 28)\n",
    "        # images[i][:] = img\n",
    "        images.append(img)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def load_data() -> tuple:\n",
    "    x_train, y_train = read_images_labels(training_images_filepath, training_labels_filepath)\n",
    "    x_test, y_test = read_images_labels(test_images_filepath, test_labels_filepath)\n",
    "    return (x_train, y_train),(x_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{type(X_train[0])}\")\n",
    "# mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:42:05.046193Z",
     "start_time": "2024-09-24T15:42:04.900436Z"
    }
   },
   "source": [
    "X_train = np.asarray(X_train)/255\n",
    "y_train = np.asarray(y_train)\n",
    "X_test  = np.asarray(X_test)/255\n",
    "y_test  = np.asarray(y_test)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Activation functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Linear:\n",
    "$ \\begin{align}\n",
    "f(\\mathbf z) &= \\mathbf z \\\\\n",
    "\\rightarrow \\frac{\\partial f(\\mathbf z)}{\\partial \\mathbf z} &=\\mathbf 1 \\\\ \n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:42:11.221832Z",
     "start_time": "2024-09-24T15:42:11.218684Z"
    }
   },
   "source": [
    "def linear(z): return z\n",
    "def grad_linear(z): return 1"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. ReLU:\n",
    "$\\begin{align}\n",
    "ReLU(\\mathbf z) &= \\max(\\mathbf z, \\mathbf 0) \\\\\n",
    "\\rightarrow \\frac{\\partial ReLU(\\mathbf z)}{\\partial \\mathbf z} &= \\begin{cases}\n",
    "z_i = 1 \\text{ if } z_i > 0 \\\\\n",
    "z_i = 0 \\text{ if } z_i \\leqslant 0 \\\\\n",
    "\\end{cases} \\\\\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:42:14.470483Z",
     "start_time": "2024-09-24T15:42:14.459916Z"
    }
   },
   "source": [
    "def relu(z): return np.maximum(0, z)\n",
    "def grad_relu(z): return np.array([1 if z_i > 0 else 0 for z_i in z])"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:42:37.533687Z",
     "start_time": "2024-09-24T15:42:37.528307Z"
    }
   },
   "source": [
    "z = np.array([1,-6, 3, 4, 0])\n",
    "relu_z = relu(z)\n",
    "relu_z\n",
    "grad_relu_z = grad_relu(relu_z)\n",
    "grad_relu_z"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Sigmoid:\n",
    "$\\begin{align}\n",
    "\\sigma(\\mathbf z) &= \\frac{1}{1 + e^{-z}} \\\\\n",
    "\\rightarrow \\frac{\\partial\\sigma(\\mathbf z)}{\\partial \\mathbf z} &= \\sigma(\\mathbf z)\\cdot\\left(1 - \\sigma(\\mathbf z)\\right) \\\\ \n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:42:40.587682Z",
     "start_time": "2024-09-24T15:42:40.585006Z"
    }
   },
   "source": [
    "def sigmoid(z): return 1/(1 + np.exp(-z))\n",
    "def grad_sigmoid(z): return sigmoid(z) * (1 - sigmoid(z))    "
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:42:41.978820Z",
     "start_time": "2024-09-24T15:42:41.974734Z"
    }
   },
   "source": [
    "z = np.array([1,-6, 3, 4, 0])\n",
    "sigmoid(z)\n",
    "grad_sigmoid(z)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19661193, 0.00246651, 0.04517666, 0.01766271, 0.25      ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1.3. Softmax:\n",
    "$\\begin{align}\n",
    "\\sigma(\\mathbf z) &= \\frac{e^{\\mathbf z}}{\\sum_{i=1}^{C}e^{z_i}} \\\\\n",
    "\\rightarrow \\frac{\\partial \\sigma(\\mathbf z)}{\\partial \\mathbf z} &= \\sigma(z_i) \\cdot (\\delta_{ij} - \\sigma(z_j)) \n",
    "\\rightarrow \\delta_{ij} = \\begin{cases} \n",
    "1 \\text{ if } i = j \\\\\n",
    "0 \\text{ if } i \\neq j  \n",
    "\\end{cases} \\\\\n",
    "&= diag(\\mathbf z) - \\mathbf z * \\mathbf z^T \\\\\n",
    "C &\\text{ is number of class} \\\\\n",
    "diag &\\text{ is diagonal matrix }\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:42:44.393157Z",
     "start_time": "2024-09-24T15:42:44.389639Z"
    }
   },
   "source": [
    "def softmax(z): return np.exp(z)/np.sum(np.exp(z))\n",
    "def grad_softmax(z): return np.diag(z) - np.outer(z,z)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:42:45.141680Z",
     "start_time": "2024-09-24T15:42:45.137562Z"
    }
   },
   "source": [
    "z = np.array([1,-6, 3, 4, 0])\n",
    "softmax(z)\n",
    "grad_softmax(z)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   6,  -3,  -4,   0],\n",
       "       [  6, -42,  18,  24,   0],\n",
       "       [ -3,  18,  -6, -12,   0],\n",
       "       [ -4,  24, -12, -12,   0],\n",
       "       [  0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loss function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Cross Entropy:\n",
    "$\\begin{align}\n",
    "CrossEntropy = - \\log(\\hat{y}_{true})\\\\\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Categorical Crossentropy:\n",
    "$\\begin{align}\n",
    "Y &\\text{ is label in one-hot matrix } N \\times C  \\\\\n",
    "\\hat{Y} &\\text{ is predicted matrix } N \\times C \\\\\n",
    "C &\\text{ is number of classes}\\\\\n",
    "L &= -\\sum_{i=1}^{C} Y_i \\log(\\hat{Y}_{i}) \\\\\n",
    "\\hat{Y}_{i,j} &= \\frac{exp(Z_{i,j})}{\\sum_{k=1}^{C} exp(Z_{i,k})} \\\\\n",
    "\\rightarrow \\mathcal L &= -\\frac{1}{N} \\sum_{i=1}^{N}\\sum_{j=1}^{C} Y_{i,j} \\log(\\hat{Y}_{i,j}) \\\\\n",
    "&= -\\frac{1}{N} \\sum_{i=1}^{N} \\log(\\hat{Y}_{i,true}) \\\\\n",
    "\\hat{Y}_{i,true} &\\text{ is predicted result corresponding to one-hot is 1}\n",
    "\\end{align}$\n",
    "\n",
    "Gradient:\n",
    "$\\begin{align}\n",
    "\\frac{\\partial L}{\\partial Z} &= \\hat{Y}_{i,j} - Y_{i,j} \\\\\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Sparse Categorical Crossentropy:\n",
    "$ \\begin{align}\n",
    "\\hat{Y} &= A_n = softmax(Z) \\\\\n",
    "Z &\\text{ is } n \\times C \\text{ matrix. n is number of samples, C is number of classes} \\\\\n",
    "CrossEntropy_i &= -\\log(\\hat{y}_{i, y_{sparse}}) \\\\\n",
    "CrossEntropy &\\text{ is a vector size n} \\\\\n",
    "\\rightarrow \\frac{\\partial L}{\\partial Z_{i,j}} &= \\hat{Y}_{i,j} - \\delta(j, y_{sparse,i}) \n",
    "\\rightarrow \\delta(j, y_{sparse,i}) = \\begin{cases}\n",
    "1 \\text{ if } j = y_{sparse,i} \\\\\n",
    "0 \\text{ if } j \\neq y_{sparse,i}\\\\\n",
    "\\end{cases} \\\\\n",
    "\\rightarrow \\frac{\\partial L}{\\partial Z_n} &= \\hat{Y} - Y = \\hat{Y} - SparseLabels \\\\\n",
    "SparseLabels &\\text{ can be considered as one-hot matrix}\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:45:30.670115Z",
     "start_time": "2024-09-24T15:45:30.666928Z"
    }
   },
   "source": [
    "# should apply the Vectorization\n",
    "def delta_kronecker_matrix(y_train, mY_pred):\n",
    "    \"\"\"\n",
    "    Transform to one-hot encoding\n",
    "    y_train: a vector size n\n",
    "    mY_pred: a matrix (C, n)\n",
    "    \"\"\"\n",
    "    mY_train = np.zeros(shape=mY_pred.shape)\n",
    "    for i in range(len(y_train)): mY_train[i][y_train[i]] = 1\n",
    "    return mY_train\n",
    "\n",
    "def sparse_categorical_crossentropy(y_train, mY_pred):\n",
    "    y_pred = np.array([mY_pred[i][y_train[i]] for i in range(len(y_train))])\n",
    "    return -np.sum(np.log(y_pred))\n",
    "\n",
    "def grad_sparse_categorical_crossentropy_Z(y_train, mY_pred):\n",
    "    return mY_pred - delta_kronecker_matrix(y_train=y_train, mY_pred=mY_pred)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T15:45:35.441411Z",
     "start_time": "2024-09-24T15:45:35.437763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test detal_kronecker_matrix\n",
    "y_train_validate = np.array([0, 2, 2, 1, 0])\n",
    "mY_pred = np.array([[0.2, 0.1 , 0.3],\n",
    "                    [0.3, 0.2, 0.7],\n",
    "                    [0.3, 0.2, 0.7],\n",
    "                    [0.3, 0.2, 0.2],\n",
    "                    [0.3, 0.2, 0.4]])\n",
    "delta = delta_kronecker_matrix(y_train_validate, mY_pred)\n",
    "delta"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T17:36:52.113520Z",
     "start_time": "2024-08-15T17:36:52.110397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cross_entropy = sparse_categorical_crossentropy(y_train_validate, mY_pred)\n",
    "print(\"%.15f\" % cross_entropy)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.136198517071602\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 8, 0, 0],\n",
       "       [0, 0, 3, 0],\n",
       "       [0, 6, 0, 0],\n",
       "       [7, 0, 0, 0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "# ex\n",
    "# [[0, 0, 0, 0],\n",
    "#  [5, 8, 0, 0],\n",
    "#  [0, 0, 3, 0],\n",
    "#  [0, 6, 0, 0]]\n",
    "#\n",
    "\n",
    "data = np.array([5, 8, 3, 6, 7])        # values\n",
    "indices = np.array([0, 1, 2, 1, 0])     # col index for each value\n",
    "indptr = np.array([0, 2, 3, 4, 5])      # start - end in data values\n",
    "csr_m = csr_matrix((data, indices, indptr), shape=(4, 4))\n",
    "csr_m.toarray()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Optimizers: "
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.1. SGD\n",
    "$\\begin{align}\n",
    "\\theta &= \\theta - \\eta \\cdot \\nabla_{\\theta} L(\\theta, x_i, y_i) \\\\\n",
    "\\theta &\\text{ is weight}\\\\\n",
    "\\eta &\\text{ is learning rate}\\\\\n",
    "\\nabla_{\\theta} L(\\theta, x_i, y_i) &\\text{ is gradient respect to }\\theta \\text{ of }(x_i, y_i) \\\\\n",
    "\\end{align}$"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.2. RMSProps:\n",
    "$\\begin{align}\n",
    "v_{t-1} &= \\beta v_{t-1} + (1 + \\beta)g_t^2 \\\\\n",
    "\\\\\n",
    "\\theta_t &= \\theta_{t-1} - \\frac{\\eta}{\\sqrt{v_t} + \\epsilon} g_t \\\\\n",
    "\\eta &\\text{ is learning rate} \\\\\n",
    "v_t &\\text{ is velocity at } t \\text{ time} \\\\\n",
    "g_t &\\text{ is gradient at } t \\text{ time} \\\\\n",
    "\\epsilon &\\text{ is very small number - avoid device by 0} \\\\\n",
    "\\theta &\\text{ is weight matrix or bias vector} \\\\\n",
    "\\end{align}$"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def optimize_RMSProps(w: np.ndarray, learning_rate=0.01, beta=0.99, epsilon=1e-7, loss=None, gradient=None):\n",
    "    \"\"\"\n",
    "    update weight matrix or bias\n",
    "    :param w: weight matrix or bias\n",
    "    :param learning_rate: \n",
    "    :param beta: \n",
    "    :param epsilon: default\n",
    "    :param loss: \n",
    "    :param gradient: \n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    v = 0 \n",
    "    epochs = 1000\n",
    "    \n",
    "    # RMSProp\n",
    "    for epoch in range(epochs):\n",
    "        g = gradient(w)\n",
    "        v = beta * v + (1 - beta) * g ** 2\n",
    "        w = w - learning_rate * g / (np.sqrt(v) + epsilon)\n",
    "    \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}: w = {w}, Loss = {loss(w)}')\n",
    "    print(f'Final w: {w}, Final Loss: {loss(w)}')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3.3. Adagrad\n",
    "$\\begin{align}\n",
    "G_t &= G_{t-1} + g_t^2 \\\\\n",
    "\\theta_t &= \\theta_{t-1} - \\frac{\\eta}{\\sqrt{G_t - \\epsilon}} \\cdot g_t \\\\\n",
    "\\eta &\\text{ is learning rate} \\\\\n",
    "g_t &\\text{ is gradient at } t \\text{ time} \\\\\n",
    "\\epsilon &\\text{ is very small number - avoid device by 0} \\\\\n",
    "\\theta &\\text{ is weight matrix or bias vector} \\\\\n",
    "G &\\text{ sum of square of gradient} \\\\\n",
    "\\end{align}$"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.4. Adaprops:"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.5. Adamax:"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.6.Adam: "
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Demo NN\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.1. Load/Prepare data"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.2. Neural network manually:\n",
    "- Flat 28 x 28 data\n",
    "- There are 03 layers: `[32, \"relu\"] [128, \"sigmoid\"] [10, \"softmax\"]`\n",
    "- Loss func: `SparseCategoricalCrossentropy`, `digits = False`\n",
    "- Optimizer: `RMSProp` with `learning_rate=1e-3`\n",
    "- **(opt)** metrics: `accuracy`"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.3. Flat input data:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T17:13:14.183642Z",
     "start_time": "2024-09-24T17:13:14.179883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def flat_data(imp_data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flat data from 02 dim matrix to vector\n",
    "    :param imp_data: (n, m_0, m_1) matrix, n is number of rows \n",
    "    :return: matrix: (n, m_0 * m_1)\n",
    "    \"\"\"\n",
    "    return imp_data.reshape((imp_data.shape[0],imp_data.shape[1]* imp_data.shape[2]))"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T17:21:05.956240Z",
     "start_time": "2024-09-24T17:21:05.950674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "marr = np.array([[[1, 2, 3, 3],[4, 5, 6, 6],[7, 8, 9, 9]],\n",
    "        [[1, 2, 3, 3],[4, 5, 6, 6],[7, 8, 9, 9]],\n",
    "        [[1, 2, 3, 3],[4, 5, 6, 6],[7, 8, 9, 9]],\n",
    "        [[1, 2, 3, 3],[4, 5, 6, 6],[7, 8, 9, 9]],\n",
    "        [[1, 2, 3, 3],[4, 5, 6, 6],[7, 8, 9, 9]]])\n",
    "x_0 = flat_data(marr)\n",
    "x_0\n",
    "# marr.shape\n",
    "# X_train.shape\n",
    "x_1 = X_train[:5].copy()\n",
    "# x_1.shape\n",
    "x_1 = x_1.reshape((x_1.shape[0], x_1.shape[1] * x_1.shape[2]))\n",
    "x_1.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 784)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.4. Loop"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class DenseLayer (object):\n",
    "    activation_map = {\"linear\": linear, \"relu\": relu, \"sigmoid\": sigmoid, \"softmax\": softmax}\n",
    "    grad_map = {\"linear\": grad_linear, \"relu\": grad_relu, \"sigmoid\": grad_sigmoid, \"softmax\": grad_softmax}\n",
    "    def __init__(self, input_size, output_size, activation = 'linear'):\n",
    "        self.activation_func = self.activation_map['linear']\n",
    "        self.grad_func = self.grad_map['linear']\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.activation = activation.lower()\n",
    "        self.weight = np.random.rand(self.output_size)\n",
    "        self.bias = np.random.random()\n",
    "        self.init()\n",
    "        return\n",
    "    def init(self) -> None:\n",
    "        self.activation_func = self.activation_map[self.activation] if self.activation in self.activation_map else self.activation_map['linear']\n",
    "        self.grad_func = self.grad_map[self.activation] if self.activation in self.grad_map else self.grad_map['linear']\n",
    "        return None\n",
    "    pass\n",
    "\n",
    "def fit(X_train, epoch=1) -> list[np.ndarray] | None:\n",
    "    \"\"\"\n",
    "    :param X_train: matrix(n, m) n - features, m - number of rows\n",
    "    :param epoch: \n",
    "    :return: list of weight matrix, from 0  \n",
    "    \"\"\"\n",
    "    model = list[np.ndarray]\n",
    "    # [32, \"relu\"] [128, \"sigmoid\"] [10, \"softmax\"]\n",
    "    # X_treated shape [m ]\n",
    "    X_treated = flat_data(X_train).transpose()\n",
    "    if X_treated is not None and len(X_treated) > 0:\n",
    "        input_size = X_treated.shape[1]\n",
    "        Weight = list[DenseLayer]\n",
    "        Weight.append(DenseLayer(input_size=input_size  , output_size=32    , activation='relu'))\n",
    "        Weight.append(DenseLayer(input_size=32          , output_size=128   , activation='sigmoid'))\n",
    "        Weight.append(DenseLayer(input_size=128         , output_size=10    , activation='softmax'))\n",
    "        for i in range(epoch):\n",
    "            # Forward propagation\n",
    "            \n",
    "            # Calculate Cost function\n",
    "            \n",
    "            # Back propagation\n",
    "        \n",
    "            pass\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T04:26:36.389440Z",
     "start_time": "2024-08-18T04:26:36.329514Z"
    }
   },
   "source": [
    "def show_image(img_data: np.ndarray) -> tuple:\n",
    "    fig, axes = plt.subplots(figsize=(1.60, 1.20))\n",
    "    axes.imshow(X=img_data, cmap=\"gray\")\n",
    "    return fig, axes\n",
    "\n",
    "# print(y_test[5854])\n",
    "show_image(X_test[4823])\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 160x120 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T04:27:19.525614Z",
     "start_time": "2024-08-18T04:27:19.406120Z"
    }
   },
   "cell_type": "code",
   "source": "show_image(X_train[0])",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 160x120 with 1 Axes>, <Axes: >)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 160x120 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2. Linear and Activation Function:"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.3. Loss/Cost Function"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.4. Optimizer"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T17:38:20.402447Z",
     "start_time": "2024-08-15T17:38:20.396792Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
    "# tf.config.experimental_connect_to_cluster(resolver)\n",
    "# # This is the TPU initialization code that has to be at the beginning.\n",
    "# tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "# print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
