{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, Masking\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import get_file, to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from module.conf import PROJECT_DIR\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "strategy  = tf.distribute.get_strategy()\n",
    "with strategy.scope():\n",
    "    print(f\"{tf.config.list_physical_devices('GPU') }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_file = PROJECT_DIR + \"/data/lstm/truyen_kieu_data.txt\"\n",
    "pre_file = PROJECT_DIR + \"/data/lstm/truyen_kieu_data_pre.txt\"\n",
    "\n",
    "def pre_data() -> None:\n",
    "    with open(file=org_file, mode=\"rt\") as i_f:\n",
    "        with open(file=pre_file, mode=\"wt\") as o_f:\n",
    "            for line in i_f:\n",
    "                if \"\" == line.strip(): continue\n",
    "                a_word = line.split()\n",
    "                pre_word = \"\"\n",
    "                for word in a_word:\n",
    "                    tmp_line = \"\".join(filter(str.isalpha, word.strip()))\n",
    "                    pre_word = \" \".join((pre_word, tmp_line))\n",
    "                    pass\n",
    "                pre_word = pre_word.strip().lower()\n",
    "                o_f.write(f\"{pre_word}\\n\") \n",
    "                pass\n",
    "            pass\n",
    "        pass\n",
    "    return\n",
    "\n",
    "def load_data() -> tuple:\n",
    "    rs: map = {}\n",
    "    ls = []\n",
    "    tmp_line = \"\"\n",
    "    with open(file=pre_file, mode=\"rt\") as i_f:\n",
    "        count = 0\n",
    "        for line in i_f:\n",
    "            line = line.strip()\n",
    "            if \"\" == line: continue\n",
    "            if count % 2 == 0 and tmp_line!=\"\":\n",
    "                ls.append(tmp_line.strip())\n",
    "                tmp_line = \"\"\n",
    "                pass\n",
    "            tmp_line += (\" | \" if tmp_line!=\"\" else \"\") + line\n",
    "            a_word = line.split()\n",
    "            for word in a_word:\n",
    "                if word not in rs:\n",
    "                    rs[word] = 0\n",
    "                    pass\n",
    "                rs[word]+=1\n",
    "                pass\n",
    "            pass\n",
    "            count+=1\n",
    "        pass\n",
    "    return rs, ls\n",
    "\n",
    "pre_data()\n",
    "bag_of_words, coupled_lines = load_data()\n",
    "bag_of_words[\"|\"] = len(coupled_lines)\n",
    "# ix_to_word = [*bag_of_words.keys()]\n",
    "keys = [*bag_of_words.keys()]\n",
    "word_to_ix = { w:i for i,w in enumerate(keys) }\n",
    "ix_to_word = { i:w for i,w in enumerate(keys) }\n",
    "# coupled_lines\n",
    "# values = [*bag_of_word.values()]\n",
    "# sum(values)\n",
    "# len(bag_of_words)\n",
    "# ix_to_word\n",
    "X_train = [[word_to_ix[word] for word in coupled_line.split()] for coupled_line in coupled_lines]\n",
    "\n",
    "delta_line = 4\n",
    "# y_train = [line[5] for line in X_train[delta_line:]]\n",
    "y_train = [*X_train[delta_line:]]\n",
    "y_train = [e[5] for e in y_train]\n",
    "for c in range(delta_line):\n",
    "    y_train.append(X_train[c][5])\n",
    "    pass\n",
    "\n",
    "total_word = len(bag_of_words)\n",
    "max_input_len = 15\n",
    "X_train = np.asarray(a=X_train, dtype=int)\n",
    "y_train = np.asarray(y_train) #.reshape(X_train.shape[0], 1)\n",
    "# print(y_train.shape)\n",
    "y_train = to_categorical(y_train, num_classes=total_word, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM-RNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 15, 1024)          2451456   \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 15, 400)          1972800   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 15, 512)          1345536   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 15, 512)           0         \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 128)               328192    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1197)              154413    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2394)              2868012   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,120,409\n",
      "Trainable params: 9,120,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model: tf.keras.Model = tf.keras.Sequential(name=\"LSTM-RNN\")\n",
    "# input = tf.keras.layers.Input(shape=(15))\n",
    "embedding_1 = tf.keras.layers.Embedding(input_dim=total_word, output_dim=1024, input_length=max_input_len)\n",
    "bidrect_1 = tf.keras.layers.Bidirectional(\\\n",
    "    layer=tf.keras.layers.LSTM(units=160, return_sequences=True, go_backwards=False),\\\n",
    "    backward_layer=tf.keras.layers.LSTM(units=240, return_sequences=True, go_backwards=True))\n",
    "bidrect_2 = tf.keras.layers.Bidirectional(layer=tf.keras.layers.LSTM(units=256, return_sequences=True))\n",
    "dropout = tf.keras.layers.Dropout(rate=0.2)\n",
    "lstm = tf.keras.layers.LSTM(units=128)\n",
    "output_1 = tf.keras.layers.Dense(units=(total_word + 1)/2, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "output_2 = tf.keras.layers.Dense(units=total_word, activation=\"softmax\")\n",
    "\n",
    "# model.add(input)\n",
    "model.add(embedding_1)\n",
    "# model.add(bidrect_1)\n",
    "model.add(bidrect_2)\n",
    "model.add(dropout)\n",
    "model.add(lstm)\n",
    "model.add(output_1)\n",
    "model.add(output_2)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_soft_device_placement(True) \n",
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "# loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "loss_fn = tf.keras.losses.categorical_crossentropy\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "              loss=loss_fn,\n",
    "              metrics=[\"accuracy\"])\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#               loss=loss_fn,\n",
    "#               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation LSTM-RNN/embedding_2/embedding_lookup: Could not satisfy explicit device specification '' because the node {{colocation_node LSTM-RNN/embedding_2/embedding_lookup}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssignSubVariableOp: GPU CPU \nRealDiv: GPU CPU \nSqrt: GPU CPU \nAssignVariableOp: GPU CPU \nUnsortedSegmentSum: GPU CPU \nIdentity: GPU CPU \nStridedSlice: CPU \nConst: GPU CPU \nNoOp: GPU CPU \nMul: GPU CPU \nShape: GPU CPU \n_Arg: GPU CPU \nResourceScatterAdd: GPU CPU \nUnique: GPU CPU \nReadVariableOp: GPU CPU \nAddV2: GPU CPU \nResourceGather: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  lstm_rnn_embedding_2_embedding_lookup_17096 (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  adam_adam_update_readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  adam_adam_update_readvariableop_2_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  LSTM-RNN/embedding_2/embedding_lookup (ResourceGather) \n  LSTM-RNN/embedding_2/embedding_lookup/Identity (Identity) \n  Adam/Adam/update/Unique (Unique) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/Shape (Shape) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack_1 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack_2 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice (StridedSlice) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/UnsortedSegmentSum (UnsortedSegmentSum) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp (ReadVariableOp) \n  Adam/Adam/update/mul_1 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignVariableOp (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ResourceScatterAdd (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_1 (ReadVariableOp) \n  Adam/Adam/update/mul_2 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul_3 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_2 (ReadVariableOp) \n  Adam/Adam/update/mul_4 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignVariableOp_1 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ResourceScatterAdd_1 (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_3 (ReadVariableOp) \n  Adam/Adam/update/Sqrt (Sqrt) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul_5 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/add (AddV2) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/truediv (RealDiv) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignSubVariableOp (AssignSubVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps/NoOp (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps/NoOp_1 (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n\n\t [[{{node LSTM-RNN/embedding_2/embedding_lookup}}]] [Op:__inference_train_function_18291]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/hiepnq/Working/training/python/learn-python/module/ml/nn/rnn_lstm_1.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hiepnq/Working/training/python/learn-python/module/ml/nn/rnn_lstm_1.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# strategy  = tf.distribute.get_strategy()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hiepnq/Working/training/python/learn-python/module/ml/nn/rnn_lstm_1.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m strategy\u001b[39m.\u001b[39mscope():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hiepnq/Working/training/python/learn-python/module/ml/nn/rnn_lstm_1.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# with tf.device('/cpu:0'):\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hiepnq/Working/training/python/learn-python/module/ml/nn/rnn_lstm_1.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# with tf.device(\"/gpu:0\"):\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hiepnq/Working/training/python/learn-python/module/ml/nn/rnn_lstm_1.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mX_train, y\u001b[39m=\u001b[39;49my_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hiepnq/Working/training/python/learn-python/module/ml/nn/rnn_lstm_1.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/conda/envs/learn-python/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/conda/envs/learn-python/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation LSTM-RNN/embedding_2/embedding_lookup: Could not satisfy explicit device specification '' because the node {{colocation_node LSTM-RNN/embedding_2/embedding_lookup}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAssignSubVariableOp: GPU CPU \nRealDiv: GPU CPU \nSqrt: GPU CPU \nAssignVariableOp: GPU CPU \nUnsortedSegmentSum: GPU CPU \nIdentity: GPU CPU \nStridedSlice: CPU \nConst: GPU CPU \nNoOp: GPU CPU \nMul: GPU CPU \nShape: GPU CPU \n_Arg: GPU CPU \nResourceScatterAdd: GPU CPU \nUnique: GPU CPU \nReadVariableOp: GPU CPU \nAddV2: GPU CPU \nResourceGather: GPU CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  lstm_rnn_embedding_2_embedding_lookup_17096 (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  adam_adam_update_readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  adam_adam_update_readvariableop_2_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0\n  LSTM-RNN/embedding_2/embedding_lookup (ResourceGather) \n  LSTM-RNN/embedding_2/embedding_lookup/Identity (Identity) \n  Adam/Adam/update/Unique (Unique) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/Shape (Shape) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack_1 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice/stack_2 (Const) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/strided_slice (StridedSlice) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/UnsortedSegmentSum (UnsortedSegmentSum) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp (ReadVariableOp) \n  Adam/Adam/update/mul_1 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignVariableOp (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ResourceScatterAdd (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_1 (ReadVariableOp) \n  Adam/Adam/update/mul_2 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul_3 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_2 (ReadVariableOp) \n  Adam/Adam/update/mul_4 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignVariableOp_1 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ResourceScatterAdd_1 (ResourceScatterAdd) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/ReadVariableOp_3 (ReadVariableOp) \n  Adam/Adam/update/Sqrt (Sqrt) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/mul_5 (Mul) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/add (AddV2) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/truediv (RealDiv) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/AssignSubVariableOp (AssignSubVariableOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps/NoOp (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps/NoOp_1 (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n  Adam/Adam/update/group_deps (NoOp) /job:localhost/replica:0/task:0/device:GPU:0\n\n\t [[{{node LSTM-RNN/embedding_2/embedding_lookup}}]] [Op:__inference_train_function_18291]"
     ]
    }
   ],
   "source": [
    "# strategy  = tf.distribute.get_strategy()\n",
    "with strategy.scope():\n",
    "# with tf.device('/cpu:0'):\n",
    "# with tf.device(\"/gpu:0\"):\n",
    "    model.fit(x=X_train, y=y_train, epochs=2, batch_size=64, verbose=1)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_couple_line = 2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
