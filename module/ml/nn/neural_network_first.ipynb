{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "import random as rd\n",
    "\n",
    "from array import array\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# my project\n",
    "from module.conf import PROJECT_DIR\n",
    "\n",
    "# %matplotlib tk\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data:\n",
    "- Train data: 60k 28x28 images\n",
    "- Test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path = \"/data/sample/mnist\"\n",
    "training_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-images.idx3-ubyte\"])\n",
    "training_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-labels.idx1-ubyte\"])\n",
    "test_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-images.idx3-ubyte\"])\n",
    "test_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-labels.idx1-ubyte\"])\n",
    "\n",
    "def read_images_labels(images_filepath, labels_filepath) -> tuple:\n",
    "    labels = []\n",
    "    with open(labels_filepath, 'rb') as file:\n",
    "        magic, size = struct.unpack(\">II\", file.read(8))\n",
    "        if magic != 2049:\n",
    "            raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "        # labels = array(\"B\", file.read())\n",
    "        labels = array(\"B\", file.read())\n",
    "\n",
    "    with open(images_filepath, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "        image_data = array(\"B\", file.read())       \n",
    "     \n",
    "    images = []\n",
    "    # for i in range(size):\n",
    "    #     images.append([0] * rows * cols)\n",
    "    for i in range(size):\n",
    "        img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "        img = img.reshape(28, 28)\n",
    "        # images[i][:] = img\n",
    "        images.append(img)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def load_data() -> tuple:\n",
    "    x_train, y_train = read_images_labels(training_images_filepath, training_labels_filepath)\n",
    "    x_test, y_test = read_images_labels(test_images_filepath, test_labels_filepath)\n",
    "    return (x_train, y_train),(x_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{type(X_train[0])}\")\n",
    "# mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)/255\n",
    "y_train = np.asarray(y_train)\n",
    "X_test  = np.asarray(X_test)/255\n",
    "y_test  = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(layers=[\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28,)),\n",
    "    tf.keras.layers.Dense(units=32, activation=tf.keras.activations.relu),\n",
    "    # tf.keras.layers.Dense(units=128, activation=tf.keras.activations.hard_sigmoid),\n",
    "    # tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model(X_train[0]).numpy()\n",
    "# predictions\n",
    "# tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# loss_fn = tf.keras.losses.mae\n",
    "# model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "#               metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.FalseNegatives()])\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "              loss=loss_fn,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "   1/1875 [..............................] - ETA: 4:39 - loss: 2.3795 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-28 20:52:40.362753: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 497us/step - loss: 0.3611 - accuracy: 0.8992\n",
      "Epoch 2/24\n",
      "1875/1875 [==============================] - 1s 511us/step - loss: 0.1987 - accuracy: 0.9437\n",
      "Epoch 3/24\n",
      "1875/1875 [==============================] - 1s 491us/step - loss: 0.1540 - accuracy: 0.9552\n",
      "Epoch 4/24\n",
      "1875/1875 [==============================] - 1s 489us/step - loss: 0.1276 - accuracy: 0.9625\n",
      "Epoch 5/24\n",
      "1875/1875 [==============================] - 1s 467us/step - loss: 0.1106 - accuracy: 0.9671\n",
      "Epoch 6/24\n",
      "1875/1875 [==============================] - 1s 485us/step - loss: 0.0982 - accuracy: 0.9702\n",
      "Epoch 7/24\n",
      "1875/1875 [==============================] - 1s 541us/step - loss: 0.0879 - accuracy: 0.9732\n",
      "Epoch 8/24\n",
      "1875/1875 [==============================] - 1s 513us/step - loss: 0.0803 - accuracy: 0.9758\n",
      "Epoch 9/24\n",
      "1875/1875 [==============================] - 1s 524us/step - loss: 0.0739 - accuracy: 0.9779\n",
      "Epoch 10/24\n",
      "1875/1875 [==============================] - 1s 511us/step - loss: 0.0682 - accuracy: 0.9793\n",
      "Epoch 11/24\n",
      "1875/1875 [==============================] - 1s 509us/step - loss: 0.0628 - accuracy: 0.9806\n",
      "Epoch 12/24\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 0.0599 - accuracy: 0.9811\n",
      "Epoch 13/24\n",
      "1875/1875 [==============================] - 1s 477us/step - loss: 0.0550 - accuracy: 0.9827\n",
      "Epoch 14/24\n",
      "1875/1875 [==============================] - 1s 486us/step - loss: 0.0519 - accuracy: 0.9838\n",
      "Epoch 15/24\n",
      "1875/1875 [==============================] - 1s 498us/step - loss: 0.0490 - accuracy: 0.9850\n",
      "Epoch 16/24\n",
      "1875/1875 [==============================] - 1s 476us/step - loss: 0.0458 - accuracy: 0.9854\n",
      "Epoch 17/24\n",
      "1875/1875 [==============================] - 1s 482us/step - loss: 0.0438 - accuracy: 0.9860\n",
      "Epoch 18/24\n",
      "1875/1875 [==============================] - 1s 482us/step - loss: 0.0409 - accuracy: 0.9871\n",
      "Epoch 19/24\n",
      "1875/1875 [==============================] - 1s 476us/step - loss: 0.0389 - accuracy: 0.9877\n",
      "Epoch 20/24\n",
      "1875/1875 [==============================] - 1s 482us/step - loss: 0.0374 - accuracy: 0.9876\n",
      "Epoch 21/24\n",
      "1875/1875 [==============================] - 1s 472us/step - loss: 0.0348 - accuracy: 0.9892\n",
      "Epoch 22/24\n",
      "1875/1875 [==============================] - 1s 476us/step - loss: 0.0332 - accuracy: 0.9896\n",
      "Epoch 23/24\n",
      "1875/1875 [==============================] - 1s 487us/step - loss: 0.0315 - accuracy: 0.9903\n",
      "Epoch 24/24\n",
      "1875/1875 [==============================] - 1s 481us/step - loss: 0.0293 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2865ba410>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train, X_test = np.asarray(X_train) / 255.0, np.asarray(X_test) / 255.0\n",
    "# print(X_test)\n",
    "model.fit(X_train, y_train, epochs=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.1298 - accuracy: 0.9695 - 123ms/epoch - 394us/step\n",
      "- [12]:img[3330]:[[-10.875591   -16.38675      0.69379157   3.8346877  -38.296505\n",
      "  -14.532145   -16.877678   -13.95973      3.3688135   -8.639976  ]]\n",
      "predict:3 solve:2\n",
      "- [72]:img[381]:[[-12.176191  -13.371866   -1.4244484   6.42141   -10.595364  -18.23315\n",
      "  -17.180119    8.301395   -4.7636094  -7.1644473]]\n",
      "predict:7 solve:3\n",
      "error: 2\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)\n",
    "c = 0\n",
    "for i in range(100):\n",
    "    test_indx = rd.randint(0, len(y_test)-1)\n",
    "    x_test_ = np.asarray([X_test[test_indx]])\n",
    "\n",
    "    # test_indx = rd.randint(0, len(y_train)-1)\n",
    "    # x_test_ = np.asarray([X_train[test_indx]])\n",
    "\n",
    "    result = model.predict(x=x_test_, verbose=0)\n",
    "    y_test_ = y_test\n",
    "    if result.argmax() != y_test_[test_indx]:\n",
    "        c+=1\n",
    "        print(f\"- [{i}]:img[{test_indx}]:{result}\\npredict:{result.argmax()} solve:{y_test_[test_indx]}\")\n",
    "print(f\"error: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 160x120 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image(img_data: np.ndarray) -> tuple:\n",
    "    fig, axes = plt.subplots(figsize=(1.60, 1.20))\n",
    "    axes.imshow(X=img_data, cmap=\"gray\")\n",
    "    return fig, axes\n",
    "\n",
    "# print(y_test[5854])\n",
    "show_image(X_test[381])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
    "# tf.config.experimental_connect_to_cluster(resolver)\n",
    "# # This is the TPU initialization code that has to be at the beginning.\n",
    "# tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "# print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
