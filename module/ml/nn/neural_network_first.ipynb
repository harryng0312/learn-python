{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "import random as rd\n",
    "\n",
    "from array import array\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# my project\n",
    "from module.conf import PROJECT_DIR\n",
    "\n",
    "# %matplotlib tk\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data:\n",
    "- Train data: 60k 28x28 images\n",
    "- Test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path = \"/data/sample/mnist\"\n",
    "training_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-images.idx3-ubyte\"])\n",
    "training_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-labels.idx1-ubyte\"])\n",
    "test_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-images.idx3-ubyte\"])\n",
    "test_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-labels.idx1-ubyte\"])\n",
    "\n",
    "def read_images_labels(images_filepath, labels_filepath) -> tuple:\n",
    "    labels = []\n",
    "    with open(labels_filepath, 'rb') as file:\n",
    "        magic, size = struct.unpack(\">II\", file.read(8))\n",
    "        if magic != 2049:\n",
    "            raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "        # labels = array(\"B\", file.read())\n",
    "        labels = array(\"B\", file.read())\n",
    "\n",
    "    with open(images_filepath, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "        image_data = array(\"B\", file.read())       \n",
    "     \n",
    "    images = []\n",
    "    # for i in range(size):\n",
    "    #     images.append([0] * rows * cols)\n",
    "    for i in range(size):\n",
    "        img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "        img = img.reshape(28, 28)\n",
    "        # images[i][:] = img\n",
    "        images.append(img)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def load_data() -> tuple:\n",
    "    x_train, y_train = read_images_labels(training_images_filepath, training_labels_filepath)\n",
    "    x_test, y_test = read_images_labels(test_images_filepath, test_labels_filepath)\n",
    "    return (x_train, y_train),(x_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{type(X_train[0])}\")\n",
    "# mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)/255\n",
    "y_train = np.asarray(y_train)\n",
    "X_test  = np.asarray(X_test)/255\n",
    "y_test  = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(layers=[\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28,)),\n",
    "    tf.keras.layers.Dense(units=128, activation=tf.keras.activations.relu),\n",
    "    # tf.keras.layers.Dense(units=128, activation=tf.keras.activations.hard_sigmoid),\n",
    "    # tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model(X_train[0]).numpy()\n",
    "# predictions\n",
    "# tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "#               metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.FalseNegatives()])\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "              loss=loss_fn,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 2s 794us/step - loss: 0.2971 - accuracy: 0.9155\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.1157 - accuracy: 0.9650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c8268210>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train, X_test = np.asarray(X_train) / 255.0, np.asarray(X_test) / 255.0\n",
    "# print(X_test)\n",
    "model.fit(X_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0787 - accuracy: 0.9757 - 322ms/epoch - 1ms/step\n",
      "- [7]:img[2182]:[[-5.764404    1.3666335   3.9280622   6.083356   -9.768268   -0.6613899\n",
      "  -6.9234385  -1.1513506   0.74174595 -6.844825  ]]\n",
      "predict:3 solve:1\n",
      "- [85]:img[4065]:[[ 0.60195583 -3.668417   -0.12154907  0.6203848  -1.2237803  -1.2786953\n",
      "  -2.2546344  -0.2849827  -0.32183504  1.1036285 ]]\n",
      "predict:9 solve:0\n",
      "error: 2\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)\n",
    "c = 0\n",
    "for i in range(100):\n",
    "    test_indx = rd.randint(0, len(y_test)-1)\n",
    "    x_test = np.asarray([X_test[test_indx]])\n",
    "    result = model.predict(x=x_test, verbose=0)\n",
    "    if result.argmax() != y_test[test_indx]:\n",
    "        c+=1\n",
    "        print(f\"- [{i}]:img[{test_indx}]:{result}\\npredict:{result.argmax()} solve:{y_test[test_indx]}\")\n",
    "print(f\"error: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 160x120 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image(img_data: np.ndarray) -> tuple:\n",
    "    fig, axes = plt.subplots(figsize=(1.60, 1.20))\n",
    "    axes.imshow(X=img_data, cmap=\"gray\")\n",
    "    return fig, axes\n",
    "\n",
    "show_image(X_test[9634])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
