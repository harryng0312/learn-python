{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "import random as rd\n",
    "\n",
    "from array import array\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# my project\n",
    "from module.conf import PROJECT_DIR\n",
    "\n",
    "# %matplotlib tk\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data:\n",
    "- Train data: 60k 28x28 images\n",
    "- Test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path = \"/data/sample/mnist\"\n",
    "training_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-images.idx3-ubyte\"])\n",
    "training_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-labels.idx1-ubyte\"])\n",
    "test_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-images.idx3-ubyte\"])\n",
    "test_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-labels.idx1-ubyte\"])\n",
    "\n",
    "def read_images_labels(images_filepath, labels_filepath) -> tuple:\n",
    "    labels = []\n",
    "    with open(labels_filepath, 'rb') as file:\n",
    "        magic, size = struct.unpack(\">II\", file.read(8))\n",
    "        if magic != 2049:\n",
    "            raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "        # labels = array(\"B\", file.read())\n",
    "        labels = array(\"B\", file.read())\n",
    "\n",
    "    with open(images_filepath, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "        image_data = array(\"B\", file.read())       \n",
    "     \n",
    "    images = []\n",
    "    # for i in range(size):\n",
    "    #     images.append([0] * rows * cols)\n",
    "    for i in range(size):\n",
    "        img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "        img = img.reshape(28, 28)\n",
    "        # images[i][:] = img\n",
    "        images.append(img)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def load_data() -> tuple:\n",
    "    x_train, y_train = read_images_labels(training_images_filepath, training_labels_filepath)\n",
    "    x_test, y_test = read_images_labels(test_images_filepath, test_labels_filepath)\n",
    "    return (x_train, y_train),(x_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{type(X_train[0])}\")\n",
    "# mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)/255\n",
    "y_train = np.asarray(y_train)\n",
    "X_test  = np.asarray(X_test)/255\n",
    "y_test  = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: tf.keras.models.Model = tf.keras.models.Sequential(layers=[\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28,)),\n",
    "    tf.keras.layers.Dense(units=32, activation=tf.keras.activations.relu),\n",
    "    # tf.keras.layers.Dense(units=128, activation=tf.keras.activations.hard_sigmoid),\n",
    "    # tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=10, activation=tf.keras.activations.linear)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "#               metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.FalseNegatives()])\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "              loss=loss_fn,\n",
    "              metrics=[\"accuracy\", \"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.0327 - accuracy: 0.2898 - mae: 4.3929\n",
      "Epoch 2/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.4979 - accuracy: 0.6067 - mae: 4.2916\n",
      "Epoch 3/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1051 - accuracy: 0.7399 - mae: 4.2549\n",
      "Epoch 4/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8521 - accuracy: 0.7932 - mae: 4.2663\n",
      "Epoch 5/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6961 - accuracy: 0.8242 - mae: 4.3069\n",
      "Epoch 6/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5962 - accuracy: 0.8473 - mae: 4.3583\n",
      "Epoch 7/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5285 - accuracy: 0.8622 - mae: 4.4178\n",
      "Epoch 8/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4804 - accuracy: 0.8734 - mae: 4.4750\n",
      "Epoch 9/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4440 - accuracy: 0.8818 - mae: 4.5325\n",
      "Epoch 10/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8897 - mae: 4.5916\n",
      "Epoch 11/24\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3925 - accuracy: 0.8953 - mae: 4.6418\n",
      "Epoch 12/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3732 - accuracy: 0.9000 - mae: 4.6964\n",
      "Epoch 13/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3570 - accuracy: 0.9041 - mae: 4.7430\n",
      "Epoch 14/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3432 - accuracy: 0.9070 - mae: 4.7859\n",
      "Epoch 15/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3309 - accuracy: 0.9101 - mae: 4.8313\n",
      "Epoch 16/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3203 - accuracy: 0.9124 - mae: 4.8732\n",
      "Epoch 17/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3107 - accuracy: 0.9148 - mae: 4.9109\n",
      "Epoch 18/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3021 - accuracy: 0.9169 - mae: 4.9505\n",
      "Epoch 19/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2942 - accuracy: 0.9188 - mae: 4.9855\n",
      "Epoch 20/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2870 - accuracy: 0.9206 - mae: 5.0220\n",
      "Epoch 21/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2803 - accuracy: 0.9219 - mae: 5.0526\n",
      "Epoch 22/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2743 - accuracy: 0.9239 - mae: 5.0838\n",
      "Epoch 23/24\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2686 - accuracy: 0.9251 - mae: 5.1141\n",
      "Epoch 24/24\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2634 - accuracy: 0.9265 - mae: 5.1443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c79dfed0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train, X_test = np.asarray(X_train) / 255.0, np.asarray(X_test) / 255.0\n",
    "# print(X_test)\n",
    "model.fit(X_train, y_train, epochs=24, batch_size=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.2579 - accuracy: 0.9276 - mae: 5.1828 - 127ms/epoch - 406us/step\n",
      "can not predict:0: 0.42646631598472595\n",
      "- [14]:img[4374]:[[3.0584672e-02 3.8491446e-05 1.6534200e-03 3.8785830e-03 3.1123424e-04\n",
      "  1.4395629e-01 7.9781163e-01 2.1365496e-04 1.5568922e-02 5.9831105e-03]]\n",
      "pred:0.7978116273880005\n",
      "predict:6 solve:5\n",
      "can not predict:1: 0.4688308835029602\n",
      "- [68]:img[8520]:[[2.6679375e-06 4.3249554e-03 2.3605406e-05 2.6684860e-03 6.6565983e-02\n",
      "  1.5659740e-02 1.5764410e-05 1.1236101e-02 4.0369920e-02 8.5913271e-01]]\n",
      "pred:0.859132707118988\n",
      "predict:9 solve:4\n",
      "- [78]:img[2751]:[[6.1480743e-01 7.0470800e-05 4.6826596e-03 1.0317627e-02 1.8694207e-04\n",
      "  1.2249217e-02 3.4926075e-01 3.6053790e-04 7.4979523e-03 5.6642113e-04]]\n",
      "pred:0.6148074269294739\n",
      "predict:0 solve:6\n",
      "- [81]:img[4293]:[[3.2252781e-04 4.2417298e-05 4.2032637e-03 7.8822275e-05 5.2202493e-01\n",
      "  1.6495842e-04 3.3403698e-03 1.8316665e-03 6.2841373e-03 4.6170688e-01]]\n",
      "pred:0.522024929523468\n",
      "predict:4 solve:9\n",
      "- [99]:img[2896]:[[8.6247146e-01 3.7133260e-04 3.2914330e-03 2.0783892e-02 3.7418877e-06\n",
      "  2.1966610e-02 1.0590870e-02 5.3819942e-05 8.0423191e-02 4.3778589e-05]]\n",
      "pred:0.8624714612960815\n",
      "predict:0 solve:8\n",
      "error: 5 can not pred:2\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)\n",
    "c = 0\n",
    "cp = 0\n",
    "for i in range(100):\n",
    "    test_indx = rd.randint(0, len(y_test)-1)\n",
    "    x_test_ = np.asarray([X_test[test_indx]])\n",
    "\n",
    "    # test_indx = rd.randint(0, len(y_train)-1)\n",
    "    # x_test_ = np.asarray([X_train[test_indx]])\n",
    "\n",
    "    result = model.predict(x=x_test_, verbose=0)\n",
    "    result = tf.nn.softmax(result).numpy()\n",
    "    y_test_ = y_test\n",
    "    if result.max() >= 0.5:\n",
    "        if result.argmax() != y_test_[test_indx]:\n",
    "            c+=1\n",
    "            print(f\"- [{i}]:img[{test_indx}]:{result}\\npred:{result.max()}\\npredict:{result.argmax()} solve:{y_test_[test_indx]}\")\n",
    "    else:\n",
    "        print(f\"can not predict:{cp}: {result.max()}\")\n",
    "        cp+=1\n",
    "print(f\"error: {c} can not pred:{cp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 160x120 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image(img_data: np.ndarray) -> tuple:\n",
    "    fig, axes = plt.subplots(figsize=(1.60, 1.20))\n",
    "    axes.imshow(X=img_data, cmap=\"gray\")\n",
    "    return fig, axes\n",
    "\n",
    "# print(y_test[5854])\n",
    "show_image(X_test[3333])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
    "# tf.config.experimental_connect_to_cluster(resolver)\n",
    "# # This is the TPU initialization code that has to be at the beginning.\n",
    "# tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "# print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
