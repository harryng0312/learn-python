{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.animation as animation\n",
    "import time\n",
    "import struct\n",
    "import tensorflow as tf\n",
    "import random as rd\n",
    "\n",
    "from array import array\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# my project\n",
    "from module.conf import PROJECT_DIR\n",
    "\n",
    "# %matplotlib tk\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data:\n",
    "- Train data: 60k 28x28 images\n",
    "- Test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path = \"/data/sample/mnist\"\n",
    "training_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-images.idx3-ubyte\"])\n",
    "training_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/train-labels.idx1-ubyte\"])\n",
    "test_images_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-images.idx3-ubyte\"])\n",
    "test_labels_filepath = \"\".join([PROJECT_DIR, mnist_path, \"/t10k-labels.idx1-ubyte\"])\n",
    "\n",
    "def read_images_labels(images_filepath, labels_filepath) -> tuple:\n",
    "    labels = []\n",
    "    with open(labels_filepath, 'rb') as file:\n",
    "        magic, size = struct.unpack(\">II\", file.read(8))\n",
    "        if magic != 2049:\n",
    "            raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "        # labels = array(\"B\", file.read())\n",
    "        labels = array(\"B\", file.read())\n",
    "\n",
    "    with open(images_filepath, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "        image_data = array(\"B\", file.read())       \n",
    "     \n",
    "    images = []\n",
    "    # for i in range(size):\n",
    "    #     images.append([0] * rows * cols)\n",
    "    for i in range(size):\n",
    "        img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "        img = img.reshape(28, 28)\n",
    "        # images[i][:] = img\n",
    "        images.append(img)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "def load_data() -> tuple:\n",
    "    x_train, y_train = read_images_labels(training_images_filepath, training_labels_filepath)\n",
    "    x_test, y_test = read_images_labels(test_images_filepath, test_labels_filepath)\n",
    "    return (x_train, y_train),(x_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{type(X_train[0])}\")\n",
    "# mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)/255\n",
    "y_train = np.asarray(y_train)\n",
    "X_test  = np.asarray(X_test)/255\n",
    "y_test  = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: tf.keras.models.Model = tf.keras.models.Sequential(layers=[\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28,)),\n",
    "    # tf.keras.layers.Dense(units=25, activation=tf.keras.activations.relu),\n",
    "    # tf.keras.layers.Dense(units=15, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(units=128, activation=tf.keras.activations.relu),\n",
    "    # tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(units=10, activation=tf.keras.activations.linear)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "#               loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "#               metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.FalseNegatives()])\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n",
    "              loss=loss_fn,\n",
    "              metrics=[\"accuracy\", \"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1.8262 - accuracy: 0.4816 - mae: 4.5209\n",
      "Epoch 2/24\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.9772 - accuracy: 0.7932 - mae: 4.6505\n",
      "Epoch 3/24\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5999 - accuracy: 0.8486 - mae: 4.9249\n",
      "Epoch 4/24\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4562 - accuracy: 0.8781 - mae: 5.1672\n",
      "Epoch 5/24\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3906 - accuracy: 0.8927 - mae: 5.3424\n",
      "Epoch 6/24\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3520 - accuracy: 0.9026 - mae: 5.4459\n",
      "Epoch 7/24\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3263 - accuracy: 0.9094 - mae: 5.5164\n",
      "Epoch 8/24\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3067 - accuracy: 0.9153 - mae: 5.5692\n",
      "Epoch 9/24\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2908 - accuracy: 0.9199 - mae: 5.6191\n",
      "Epoch 10/24\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2769 - accuracy: 0.9236 - mae: 5.6522\n",
      "Epoch 11/24\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2650 - accuracy: 0.9269 - mae: 5.6922\n",
      "Epoch 12/24\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2541 - accuracy: 0.9298 - mae: 5.7232\n",
      "Epoch 13/24\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2438 - accuracy: 0.9333 - mae: 5.7559\n",
      "Epoch 14/24\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2345 - accuracy: 0.9356 - mae: 5.7780\n",
      "Epoch 15/24\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2257 - accuracy: 0.9383 - mae: 5.7982\n",
      "Epoch 16/24\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.2176 - accuracy: 0.9405 - mae: 5.8243\n",
      "Epoch 17/24\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.2102 - accuracy: 0.9426 - mae: 5.8462\n",
      "Epoch 18/24\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2030 - accuracy: 0.9447 - mae: 5.8625\n",
      "Epoch 19/24\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1962 - accuracy: 0.9469 - mae: 5.8865\n",
      "Epoch 20/24\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1901 - accuracy: 0.9481 - mae: 5.9049\n",
      "Epoch 21/24\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1839 - accuracy: 0.9498 - mae: 5.9240\n",
      "Epoch 22/24\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1784 - accuracy: 0.9514 - mae: 5.9459\n",
      "Epoch 23/24\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1734 - accuracy: 0.9527 - mae: 5.9554\n",
      "Epoch 24/24\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1684 - accuracy: 0.9542 - mae: 5.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cf644750>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train, X_test = np.asarray(X_train) / 255.0, np.asarray(X_test) / 255.0\n",
    "# print(X_test)\n",
    "model.fit(X_train, y_train, epochs=24, batch_size=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.1734 - accuracy: 0.9513 - mae: 6.0099 - 207ms/epoch - 662us/step\n",
      "can not predict:4065: 0.388945072889328\n",
      "can not predict:4454: 0.46551787853240967\n",
      "- [77]:img[7338]:[[6.9893926e-04 3.3516466e-05 3.1929463e-03 1.8854003e-03 3.0333966e-01\n",
      "  6.8997144e-04 8.7273652e-03 6.5936655e-04 1.7423725e-01 5.0653553e-01]]\n",
      "pred:0.506535530090332\n",
      "predict:9 solve:4\n",
      "error: 1 can not pred:2\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test,  y_test, verbose=2)\n",
    "c = 0\n",
    "cp = 0\n",
    "for i in range(100):\n",
    "    test_indx = rd.randint(0, len(y_test)-1)\n",
    "    x_test_ = np.asarray([X_test[test_indx]])\n",
    "\n",
    "    # test_indx = rd.randint(0, len(y_train)-1)\n",
    "    # x_test_ = np.asarray([X_train[test_indx]])\n",
    "\n",
    "    result = model.predict(x=x_test_, verbose=0)\n",
    "    result = tf.nn.softmax(result).numpy()\n",
    "    y_test_ = y_test\n",
    "    if result.max() >= 0.5:\n",
    "        if result.argmax() != y_test_[test_indx]:\n",
    "            c+=1\n",
    "            print(f\"- [{i}]:img[{test_indx}]:{result}\\npred:{result.max()}\\npredict:{result.argmax()} solve:{y_test_[test_indx]}\")\n",
    "    else:\n",
    "        print(f\"can not predict:{test_indx}: {result.max()}\")\n",
    "        cp+=1\n",
    "print(f\"error: {c} can not pred:{cp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 160x120 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image(img_data: np.ndarray) -> tuple:\n",
    "    fig, axes = plt.subplots(figsize=(1.60, 1.20))\n",
    "    axes.imshow(X=img_data, cmap=\"gray\")\n",
    "    return fig, axes\n",
    "\n",
    "# print(y_test[5854])\n",
    "show_image(X_test[4454])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
    "# tf.config.experimental_connect_to_cluster(resolver)\n",
    "# # This is the TPU initialization code that has to be at the beginning.\n",
    "# tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "# print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
