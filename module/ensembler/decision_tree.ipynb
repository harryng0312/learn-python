{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T04:19:13.512366Z",
     "start_time": "2025-03-31T04:19:13.507832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from math import log2\n",
    "from module.conf import PROJECT_DIR\n",
    "\n"
   ],
   "id": "c62fc548fc750248",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "a6efe924415f379f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T04:19:13.555617Z",
     "start_time": "2025-03-31T04:19:13.553193Z"
    }
   },
   "source": [
    "# Read CSV\n",
    "def load_csv(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines[1:]:  # Ignore header\n",
    "            category, message = line.strip().split(',', 1)\n",
    "            message = message.strip('\"')  # remove ()\n",
    "            data.append([category, message])\n",
    "    return data"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T04:19:13.567187Z",
     "start_time": "2025-03-31T04:19:13.563554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract keywords in msg\n",
    "def extract_keywords(data, top_n=20):\n",
    "    word_freq = {}\n",
    "    for _, message in data:\n",
    "        words = message.lower().replace(',', ' ').replace('.', ' ').replace('!', ' ').split()\n",
    "        for word in words:\n",
    "            word_freq[word] = word_freq.get(word, 0) + 1\n",
    "\n",
    "    # sort by frequency and get top N\n",
    "    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    keywords = [word for word, _ in sorted_words[:top_n]]\n",
    "    return keywords\n",
    "\n",
    "# Extract features from msg\n",
    "def extract_features(message, keywords):\n",
    "    message = message.lower()\n",
    "    features = []\n",
    "    for keyword in keywords:\n",
    "        count = message.count(keyword)\n",
    "        features.append(count)\n",
    "    return features\n",
    "\n",
    "# Change data to number\n",
    "def preprocess_data(data, keywords):\n",
    "    processed_data = []\n",
    "    for category, message in data:\n",
    "        features = extract_features(message, keywords)\n",
    "        label = 1 if category == 'spam' else 0  # spam: 1, ham: 0\n",
    "        processed_data.append(features + [label])\n",
    "    return processed_data"
   ],
   "id": "bdf8d79ccef7a074",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T04:19:13.643939Z",
     "start_time": "2025-03-31T04:19:13.639463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate Entropy\n",
    "def calculate_entropy(labels):\n",
    "    n = len(labels)\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    unique_labels = set(labels)\n",
    "    entropy = 0\n",
    "    for label in unique_labels:\n",
    "        p = labels.count(label) / n\n",
    "        if p > 0:\n",
    "            # entropy -= p * __import__('math').log2(p)\n",
    "            entropy -= p * log2(p)\n",
    "    return entropy\n",
    "\n",
    "# Calculate Information Gain\n",
    "def calculate_information_gain(data, feature_idx, threshold):\n",
    "    labels = [row[-1] for row in data]\n",
    "    total_entropy = calculate_entropy(labels)\n",
    "    n = len(data)\n",
    "\n",
    "    left = [row for row in data if row[feature_idx] <= threshold]\n",
    "    right = [row for row in data if row[feature_idx] > threshold]\n",
    "\n",
    "    left_entropy = calculate_entropy([row[-1] for row in left])\n",
    "    right_entropy = calculate_entropy([row[-1] for row in right])\n",
    "\n",
    "    weighted_entropy = (len(left) / n) * left_entropy + (len(right) / n) * right_entropy\n",
    "    gain = total_entropy - weighted_entropy\n",
    "    return gain, left, right\n",
    "\n",
    "# find best feature and threshold\n",
    "def find_best_split(data):\n",
    "    best_gain = -1\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    best_left = None\n",
    "    best_right = None\n",
    "\n",
    "    n_features = len(data[0]) - 1  # Number of Features (trừ nhãn)\n",
    "\n",
    "    for feature_idx in range(n_features):\n",
    "        values = sorted(set(row[feature_idx] for row in data))\n",
    "        for i in range(len(values) - 1):\n",
    "            threshold = (values[i] + values[i + 1]) / 2\n",
    "            gain, left, right = calculate_information_gain(data, feature_idx, threshold)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = feature_idx\n",
    "                best_threshold = threshold\n",
    "                best_left = left\n",
    "                best_right = right\n",
    "\n",
    "    return best_feature, best_threshold, best_gain, best_left, best_right"
   ],
   "id": "23735ea9a184f18a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T04:19:13.652574Z",
     "start_time": "2025-03-31T04:19:13.649058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tree Node\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "# build Decision tree\n",
    "def build_tree(data, max_depth, depth=0):\n",
    "    labels = [row[-1] for row in data]\n",
    "\n",
    "    if len(set(labels)) == 1:  # Tất cả cùng nhãn\n",
    "        return Node(value=labels[0])\n",
    "    if depth >= max_depth:  # Đạt độ sâu tối đa\n",
    "        majority_label = max(set(labels), key=labels.count)\n",
    "        return Node(value=majority_label)\n",
    "\n",
    "    feature, threshold, gain, left, right = find_best_split(data)\n",
    "\n",
    "    if gain <= 0:  # Không còn gain\n",
    "        majority_label = max(set(labels), key=labels.count)\n",
    "        return Node(value=majority_label)\n",
    "\n",
    "    left_node = build_tree(left, max_depth, depth + 1)\n",
    "    right_node = build_tree(right, max_depth, depth + 1)\n",
    "\n",
    "    return Node(feature=feature, threshold=threshold, left=left_node, right=right_node)\n",
    "\n",
    "def predict(tree, sample):\n",
    "    if tree.value is not None:\n",
    "        return tree.value\n",
    "\n",
    "    if sample[tree.feature] <= tree.threshold:\n",
    "        return predict(tree.left, sample)\n",
    "    else:\n",
    "        return predict(tree.right, sample)"
   ],
   "id": "9bcc61ccab709955",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T04:19:13.684410Z",
     "start_time": "2025-03-31T04:19:13.682154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_test_split(data, test_size=0.2):\n",
    "    n = len(data)\n",
    "    n_test = int(n * test_size)\n",
    "    test_indices = set(__import__('random').sample(range(n), n_test))\n",
    "    train_data = [data[i] for i in range(n) if i not in test_indices]\n",
    "    test_data = [data[i] for i in range(n) if i in test_indices]\n",
    "    return train_data, test_data"
   ],
   "id": "ca03f8144704974b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-31T04:19:15.334356Z",
     "start_time": "2025-03-31T04:19:13.689267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    filename = f\"{PROJECT_DIR}/data/basic/email/spam.csv\"\n",
    "    raw_data = load_csv(filename)\n",
    "    print(f\"Loaded {len(raw_data)} samples from {filename}\")\n",
    "\n",
    "    keywords = extract_keywords(raw_data, top_n=200)  # Lấy 20 từ khóa phổ biến\n",
    "    print(f\"Feature keywords: {keywords}\")\n",
    "\n",
    "    data = preprocess_data(raw_data, keywords)\n",
    "\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "    print(f\"Train set: {len(train_data)} samples\")\n",
    "    print(f\"Test set: {len(test_data)} samples\")\n",
    "\n",
    "    max_depth = 3\n",
    "    tree = build_tree(train_data, max_depth)\n",
    "\n",
    "    def print_tree(node, indent=\"\"):\n",
    "        if node.value is not None:\n",
    "            print(f\"{indent}Leaf: {int(node.value)}\")\n",
    "        else:\n",
    "            print(f\"{indent}Feature '{keywords[node.feature]}' count <= {node.threshold}\")\n",
    "            print_tree(node.left, indent + \"  Left: \")\n",
    "            print_tree(node.right, indent + \"  Right: \")\n",
    "\n",
    "    print(\"\\nDecision Tree structure:\")\n",
    "    print_tree(tree)\n",
    "\n",
    "    correct = 0\n",
    "    for sample in test_data:\n",
    "        pred = predict(tree, sample[:-1])\n",
    "        if pred == sample[-1]:\n",
    "            correct += 1\n",
    "    accuracy = correct / len(test_data)\n",
    "    print(f\"\\nTest Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Dự đoán một tin nhắn mới\n",
    "    new_message = \"Free tickets to win a prize! Call now!\"\n",
    "    new_sample = extract_features(new_message, keywords)\n",
    "    prediction = predict(tree, new_sample)\n",
    "    print(f\"Predict new message: '{new_message}': {'spam' if prediction == 1 else 'ham'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5574 samples from /Users/hiepnq/Working/training/python/learn-python/data/basic/email/spam.csv\n",
      "Feature keywords: ['i', 'to', 'you', 'a', 'the', 'u', 'and', 'is', 'in', 'me', 'my', 'for', 'your', 'it', 'of', 'call', 'have', 'on', 'that', 'are', '2', 'now', 'so', 'but', 'not', 'or', 'can', 'at', 'do', 'will', \"i'm\", 'ur', 'be', 'if', 'get', 'with', 'just', 'we', 'this', 'no', 'up', 'when', 'from', '4', 'go', '&lt;#&gt;', 'ok', 'free', 'all', 'how', 'out', 'what', 'know', 'like', 'then', 'good', 'got', 'was', 'come', 'am', 'its', 'love', 'time', 'only', '?', 'day', 'send', 'he', 'there', 'want', 'text', 'as', 'by', 'one', \"i'll\", 'need', 'ü', 'home', 'going', 'about', 'lor', 'sorry', 'see', 'still', 'txt', 'r', 'n', 'reply', 'dont', 'back', 'our', 'she', 'stop', \"don't\", 'tell', 'mobile', 'new', 'take', 'hi', 'da', 'any', 'today', 'please', 'pls', 'think', 'been', 'they', 'her', 'later', 'k', 'did', 'dear', 'phone', 'some', 'has', 'well', 'great', 'an', 'hey', 'here', 'claim', 'hope', '&', 'oh', 'who', 'much', 'too', 'night', 'week', 'him', 'had', 'where', 'happy', 'more', 'give', 'make', 'd', \"it's\", 'work', 'should', 'way', 'yes', 'say', '1', 'wat', 'prize', 'number', 'message', 'after', 'ask', 'e', '-', '&amp;', 'tomorrow', 'yeah', 'im', 'www', 'really', 'them', 'c', 'said', 'meet', 'very', 'miss', 'why', 'last', 'already', 'life', 'would', 'cos', 'right', 'doing', 'thanks', 'babe', 'cash', 'lol', 'let', 'anything', ':)', 'find', 'also', 'every', 'win', 'sure', 'msg', 'morning', 'pick', 'care', 'won', '3', 'urgent', 'nokia', 'keep', 'b', 'contact', 'sent', 'cant', \"i've\", 'com', 'gud']\n",
      "Train set: 4460 samples\n",
      "Test set: 1114 samples\n",
      "\n",
      "Decision Tree structure:\n",
      "Feature '1' count <= 0.5\n",
      "  Left: Feature 'r' count <= 5.5\n",
      "  Left:   Left: Feature 'free' count <= 0.5\n",
      "  Left:   Left:   Left: Leaf: 0\n",
      "  Left:   Left:   Right: Leaf: 0\n",
      "  Left:   Right: Feature 'www' count <= 0.5\n",
      "  Left:   Right:   Left: Leaf: 0\n",
      "  Left:   Right:   Right: Leaf: 1\n",
      "  Right: Feature '1' count <= 1.5\n",
      "  Right:   Left: Feature 'mobile' count <= 0.5\n",
      "  Right:   Left:   Left: Leaf: 0\n",
      "  Right:   Left:   Right: Leaf: 1\n",
      "  Right:   Right: Feature 'ur' count <= 0.5\n",
      "  Right:   Right:   Left: Leaf: 1\n",
      "  Right:   Right:   Right: Leaf: 1\n",
      "\n",
      "Test Accuracy: 93.99%\n",
      "Predict new message: 'Free tickets to win a prize! Call now!': ham\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T04:19:15.340535Z",
     "start_time": "2025-03-31T04:19:15.339266Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "11ab14b67fd8fa1f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
